# GPU Cache Experiment Configuration
# Comprehensive cache pressure study with conversational vs non-conversational workloads

tag: "qwen-32b"
log_base_dir: "outputs/logs/experiments"
model_name: "qwen-32b"

defaults:
  num_prompts: 30000
  time_limit: 3600
  use_conversation_evictions: [true, false]
  mock_decoding: false
  # Global conversation eviction config (used if not specified per dataset)
  conversation_eviction_config:
    reference_recency: 100.0
    reference_time_interval: 100.0
    score_factor: 1.0

experiments:
    datasets:
      - path: "data/cw_logs_5_29_5am_6am.csv"
        cache_sizes: [64, 128, 256, 512]
        request_rates: [0.4]
      - path: "data/cw_logs_5_28_19pm_20pm.csv"
        cache_sizes: [64, 128, 256, 512]
        request_rates: []