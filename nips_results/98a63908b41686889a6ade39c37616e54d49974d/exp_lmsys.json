[
    {
        "num_requests": "4909",
        "input_tokens": "304274",
        "output_tokens": "866848",
        "mean_ttft": "170.44",
        "median_ttft": "150.80",
        "p99_ttft": "370.24",
        "hit_ratios": [
            "0.03929273084479371",
            "0.06158730158730158",
            "0.07051282051282051",
            "0.09492273730684327",
            "0.11990335246149199",
            "0.13344051446945338",
            "0.16786689843555996",
            "0.21430056121388488",
            "0.2689506785832506",
            "0.30514496873223423",
            "0.32777915941308133",
            "0.34697450486924175",
            "0.35492957746478876",
            "0.35679887925750814",
            "0.364875637755102",
            "0.3703839122486288",
            "0.37528573349468863",
            "0.3897773403862714",
            "0.38836165255441263",
            "0.38954017450885925",
            "0.3863868464052288",
            "0.3835328912846443",
            "0.39364689364689354",
            "0.4026787554090253",
            "0.4107400898262058",
            "0.4172037498169035",
            "0.42115747896273403",
            "0.42419525765001986",
            "0.428361310951239",
            "0.42878464818763323",
            "0.42760233242884355",
            "0.4275362318840579",
            "0.4298885592880622",
            "0.4285786892328022",
            "0.42966872320919736",
            "0.4298373420593785",
            "0.43105197620255487",
            "0.4290987665436211",
            "0.42591870341480315",
            "0.42623917760316826",
            "0.4293150964580994",
            "0.42821890547263675",
            "0.4270650263620386",
            "0.4253480102889998",
            "0.42334053834358654",
            "0.42284598133545526",
            "0.41751994915613294",
            "0.41472379933387393",
            "0.411398451093446",
            "0.411398451093446"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-reqrate+/client_logs/8000_lru.json"
    },
    {
        "num_requests": "6615",
        "input_tokens": "398563",
        "output_tokens": "1164458",
        "mean_ttft": "185.96",
        "median_ttft": "186.02",
        "p99_ttft": "364.80",
        "hit_ratios": [
            "0.028028028028028028",
            "0.060072815533980584",
            "0.08104517271922054",
            "0.11877789220734636",
            "0.13411896745230079",
            "0.1704878048780488",
            "0.20608251807741385",
            "0.22610809799887788",
            "0.22627857260319023",
            "0.2281340003031681",
            "0.24909066415196013",
            "0.25384707145413343",
            "0.2713983050847458",
            "0.27628291370363245",
            "0.3012490173814306",
            "0.3145417063114494",
            "0.32379723237972324",
            "0.33459319673761684",
            "0.33931203931203924",
            "0.3464325693748895",
            "0.3523255813953488",
            "0.3574950951800201",
            "0.36641068112232084",
            "0.3719143213908365",
            "0.3780465372942149",
            "0.38704478132078746",
            "0.38961414525324284",
            "0.393758168640342",
            "0.3992302177276328",
            "0.40399709302325565",
            "0.4088342283041745",
            "0.4036353916065222",
            "0.3997257232416899",
            "0.40234781785477597",
            "0.40771049281687566",
            "0.4060647379653782",
            "0.4060456579098312",
            "0.41346548750102663",
            "0.41460147354320154",
            "0.4199025965570226",
            "0.42380976320949165",
            "0.42304032789284923",
            "0.4265386150703266",
            "0.42600082731994304",
            "0.42905202183357477",
            "0.43223022206800843",
            "0.43335736397947516",
            "0.43664207098396485",
            "0.4387444885139626",
            "0.43855218855218864",
            "0.44046342397548843",
            "0.44173184357541906",
            "0.44364800698600987",
            "0.44292997238547055",
            "0.44828299188448756",
            "0.4491792238403906",
            "0.4480364219973143",
            "0.44768911283182283",
            "0.44840495566236777",
            "0.4485781916715982",
            "0.4475981190644498",
            "0.44763031737362713",
            "0.4478868597282358",
            "0.4479886585149745",
            "0.4471907823911084",
            "0.44579196183524217",
            "0.4447645254679395",
            "0.4447645254679395"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.02,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 2,
        "result_file": "lmsys-reqrate+/client_logs/8001_lru.json"
    },
    {
        "num_requests": "8306",
        "input_tokens": "484485",
        "output_tokens": "1428493",
        "mean_ttft": "203.89",
        "median_ttft": "205.34",
        "p99_ttft": "390.07",
        "hit_ratios": [
            "0.03887269193391643",
            "0.0803727431566686",
            "0.09637526652452026",
            "0.15533088235294118",
            "0.16573886639676114",
            "0.19357014388489208",
            "0.21920792079207918",
            "0.23236587510993836",
            "0.2391233766233766",
            "0.2323682256867112",
            "0.23554264589384735",
            "0.2502937720329025",
            "0.2573784722222222",
            "0.25789897363654657",
            "0.2672630696114062",
            "0.2699831365935919",
            "0.2810844499844188",
            "0.28405776481468303",
            "0.28356387306753456",
            "0.2926360315323976",
            "0.29675613170227005",
            "0.30478328440683816",
            "0.3072981958903363",
            "0.31112856768787645",
            "0.31718575631530893",
            "0.3220028004442084",
            "0.32273345527883307",
            "0.3298656655660591",
            "0.33458225667527997",
            "0.33251732293265845",
            "0.33226401475659645",
            "0.3351391378907163",
            "0.34207457014936604",
            "0.34496067579376644",
            "0.342416434294589",
            "0.3441445140100585",
            "0.3464739961377106",
            "0.34971209213051824",
            "0.35200247409927327",
            "0.35203186777252593",
            "0.3541055079203604",
            "0.3582001016891701",
            "0.3631321548591569",
            "0.36601875263379685",
            "0.3667270844122217",
            "0.37208890238963155",
            "0.37216431637032504",
            "0.3753176129752322",
            "0.37623462541930686",
            "0.3805142453711085",
            "0.38343680709534367",
            "0.3860180398433951",
            "0.38854335771963483",
            "0.3896889221370239",
            "0.3917750239098142",
            "0.39377430370501965",
            "0.3932412269653342",
            "0.39410993022415725",
            "0.39487457475045795",
            "0.3958818958818959",
            "0.3982176702143169",
            "0.40040241448692154",
            "0.40039914519347947",
            "0.4008725578808316",
            "0.39954099371435425",
            "0.39919001012487343",
            "0.3977619363395225",
            "0.3971199476354116",
            "0.39546375050627786",
            "0.39657834009707965",
            "0.39712205379280047",
            "0.39733337458043966",
            "0.3979465554384196",
            "0.3975981579858237",
            "0.39878805793674255",
            "0.40063210392020415",
            "0.4015917924096936",
            "0.40028625278104507",
            "0.4003771476463193",
            "0.40282797191265995",
            "0.4034281388558452",
            "0.40248551897582713",
            "0.40193510169156854",
            "0.40102767109281817",
            "0.40102767109281817"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8002  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.03,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 3,
        "result_file": "lmsys-reqrate+/client_logs/8002_lru.json"
    },
    {
        "num_requests": "9571",
        "input_tokens": "557844",
        "output_tokens": "1676559",
        "mean_ttft": "219.37",
        "median_ttft": "219.10",
        "p99_ttft": "448.19",
        "hit_ratios": [
            "0.04407443682664055",
            "0.0975473801560758",
            "0.11933656957928802",
            "0.16980568011958147",
            "0.1813627254509018",
            "0.20166631061738943",
            "0.21200311769290728",
            "0.22060627299807253",
            "0.2173230817511376",
            "0.2267806267806268",
            "0.2338129496402878",
            "0.23431156478366777",
            "0.23529411764705885",
            "0.23994238090338516",
            "0.24366509297620198",
            "0.24263176144244109",
            "0.24177763516765605",
            "0.2425415622864951",
            "0.24684799546678",
            "0.26146055437100213",
            "0.26494023904382474",
            "0.2718376223269301",
            "0.28197823485841267",
            "0.284020390070922",
            "0.2922682569575225",
            "0.29498941425546926",
            "0.3002482597478459",
            "0.3001751810993797",
            "0.30217331999636254",
            "0.30189673340358264",
            "0.30317223759846706",
            "0.30484873601326146",
            "0.3044247787610619",
            "0.30416764406912183",
            "0.30807199851549444",
            "0.3097072419106317",
            "0.3121220644072563",
            "0.31539718194813143",
            "0.3190620471611118",
            "0.32128176080271886",
            "0.3241899968543567",
            "0.3229080428050164",
            "0.32670345560244335",
            "0.32770620039111925",
            "0.3306010161974005",
            "0.33106638398634314",
            "0.3289907519099316",
            "0.3307950845499421",
            "0.33410678769952556",
            "0.3351073132948553",
            "0.33629133934632904",
            "0.3418269572006528",
            "0.3449035940509059",
            "0.3448470737165719",
            "0.3464743660970242",
            "0.3470683186458423",
            "0.34792611864880546",
            "0.34782331434401825",
            "0.349262868565717",
            "0.3508108991380365",
            "0.3521483746379142",
            "0.35080006337135594",
            "0.3500868580797531",
            "0.34978524165151087",
            "0.347574180312298",
            "0.347465576107755",
            "0.3477551927958641",
            "0.34870490963635015",
            "0.34805330076862273",
            "0.3480659088906509",
            "0.34843271840799434",
            "0.3471022379429968",
            "0.3485202752354864",
            "0.34844990610483284",
            "0.3479325441868004",
            "0.3482623631860666",
            "0.348719803724207",
            "0.3485250120138272",
            "0.34986550100874214",
            "0.349372227652056",
            "0.3502370858383677",
            "0.3504914112397559",
            "0.35032771804749013",
            "0.35060192845324334",
            "0.3511654188444693",
            "0.35213389121338884",
            "0.35279808677827096",
            "0.35203079159152667",
            "0.35404630009122495",
            "0.3561574170665551",
            "0.35622803743129633",
            "0.35719363274010485",
            "0.3568213642728543",
            "0.35626826471349804",
            "0.35393539720339473",
            "0.3529816846276516",
            "0.352842486421243",
            "0.352842486421243"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8003  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.04,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 4,
        "result_file": "lmsys-reqrate+/client_logs/8003_lru.json"
    },
    {
        "num_requests": "3815",
        "input_tokens": "273288",
        "output_tokens": "687031",
        "mean_ttft": "175.22",
        "median_ttft": "158.52",
        "p99_ttft": "410.19",
        "hit_ratios": [
            "0.01331967213114754",
            "0.054334554334554336",
            "0.05427782888684452",
            "0.05521235521235521",
            "0.061284046692607",
            "0.0637904468412943",
            "0.12654486835034928",
            "0.20977816067197932",
            "0.25296512657107456",
            "0.30275643922277445",
            "0.31532226939405633",
            "0.33647692825867287",
            "0.3585130702713447",
            "0.3793072014585232",
            "0.38542449286250935",
            "0.3860380504813158",
            "0.3814469659244504",
            "0.380876281795179",
            "0.3856598672892602",
            "0.38305045338293414",
            "0.3846492677017949",
            "0.38484405966412844",
            "0.3896226885311269",
            "0.3880841888154502",
            "0.3808138233582523",
            "0.37579839235281326",
            "0.3700226339173442",
            "0.36413965893477734",
            "0.35841591915076965",
            "0.3515388114008489",
            "0.34317670074932627",
            "0.3329790625996386",
            "0.3292913982569155",
            "0.32265057026612415",
            "0.31590364566470247",
            "0.31314655850077033",
            "0.3070032823092733",
            "0.30567685589519644",
            "0.30567685589519644"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.0025,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-reqrate+/client_logs/8000_ml.json"
    },
    {
        "num_requests": "3944",
        "input_tokens": "266221",
        "output_tokens": "699923",
        "mean_ttft": "167.99",
        "median_ttft": "144.88",
        "p99_ttft": "374.25",
        "hit_ratios": [
            "0.016243654822335026",
            "0.028827674567584886",
            "0.03784056508577195",
            "0.05549088086922778",
            "0.06210561275323812",
            "0.08508088675853806",
            "0.12233169129720854",
            "0.24587118084227905",
            "0.2772649572649573",
            "0.3041067146282974",
            "0.332019445539351",
            "0.3570536828963795",
            "0.3691699604743083",
            "0.3913386517050934",
            "0.4140965670340126",
            "0.42563189747241015",
            "0.4372974003686519",
            "0.44380538764011973",
            "0.4446005837206789",
            "0.4454037845103919",
            "0.44329896907216504",
            "0.444897410626288",
            "0.4448391052475792",
            "0.4546393390530665",
            "0.45732261976955735",
            "0.4646530493988122",
            "0.4639986139986141",
            "0.46176966013805865",
            "0.4616439666996268",
            "0.45821191642383285",
            "0.45095376071471693",
            "0.4480538570084666",
            "0.4444700793078587",
            "0.44066606761765686",
            "0.4343945905992498",
            "0.43270973243790634",
            "0.42704903155547486",
            "0.4202305125872004",
            "0.41497241139334884",
            "0.41497241139334884",
            "0.41497241139334884"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.005,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.5,
        "result_file": "lmsys-reqrate+/client_logs/8001_ml.json"
    },
    {
        "num_requests": "4020",
        "input_tokens": "272121",
        "output_tokens": "715227",
        "mean_ttft": "171.40",
        "median_ttft": "150.42",
        "p99_ttft": "397.23",
        "hit_ratios": [
            "0.01331967213114754",
            "0.028827674567584886",
            "0.03799392097264438",
            "0.06050096339113681",
            "0.06361829025844931",
            "0.08508088675853806",
            "0.12233169129720854",
            "0.23162675474814204",
            "0.2505982905982906",
            "0.26184052757793763",
            "0.2794639337800552",
            "0.3014413800930655",
            "0.3212450592885376",
            "0.34838257210484785",
            "0.37715415019762843",
            "0.38272043163424674",
            "0.39013538422424204",
            "0.3937437643054169",
            "0.39828126689006593",
            "0.39796498114766804",
            "0.3957650856952951",
            "0.39890857040615496",
            "0.3983856653847779",
            "0.40723426171704774",
            "0.4151794172255694",
            "0.419084882078035",
            "0.4137883488452258",
            "0.40808726601634593",
            "0.4081288392374041",
            "0.4025986078886311",
            "0.3965366661647343",
            "0.3870231019236964",
            "0.3852694473170172",
            "0.3785380329796467",
            "0.3707414282594454",
            "0.36472748562912505",
            "0.35829499043581664",
            "0.35124465677646466",
            "0.3452893937910097",
            "0.34500952660120177",
            "0.34500952660120177"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.005,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.5,
        "result_file": "lmsys-reqrate+/client_logs/8001_lru.json"
    },
    {
        "num_requests": "3900",
        "input_tokens": "278653",
        "output_tokens": "703398",
        "mean_ttft": "174.94",
        "median_ttft": "160.54",
        "p99_ttft": "418.29",
        "hit_ratios": [
            "0.01331967213114754",
            "0.054334554334554336",
            "0.05427782888684452",
            "0.055404881828748545",
            "0.06134371957156767",
            "0.0637904468412943",
            "0.12573885008060184",
            "0.19750161533491278",
            "0.23260754115772703",
            "0.27248079530049707",
            "0.28521806252412196",
            "0.3108790838666218",
            "0.3216380081502833",
            "0.33679795769511306",
            "0.3459387261040154",
            "0.3565527173501099",
            "0.3485807782599416",
            "0.3497802636835796",
            "0.342774637503072",
            "0.3420134852359916",
            "0.33955511507543223",
            "0.3381662668196516",
            "0.34042765289338583",
            "0.34205221956593074",
            "0.3398062606511795",
            "0.3347529442440572",
            "0.3281079721686646",
            "0.3262204978984804",
            "0.32416549130230365",
            "0.3183230990827079",
            "0.31223005648049024",
            "0.3016114751195325",
            "0.2958706125258087",
            "0.2896360785883452",
            "0.28334036545389635",
            "0.27775856105153934",
            "0.2718511946645456",
            "0.2683212996389892",
            "0.2683212996389892",
            "0.2683212996389892"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.0025,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-reqrate+/client_logs/8000_lru.json"
    },
    {
        "num_requests": "3843",
        "input_tokens": "275851",
        "output_tokens": "694466",
        "mean_ttft": "179.31",
        "median_ttft": "165.20",
        "p99_ttft": "436.75",
        "hit_ratios": [
            "0.01331967213114754",
            "0.05538832028898254",
            "0.05370616955170883",
            "0.05464272067252579",
            "0.06113256113256113",
            "0.06377079482439926",
            "0.12547017732401933",
            "0.20864702086470208",
            "0.24246231155778894",
            "0.2958795803557853",
            "0.30943738656987296",
            "0.3314498813425246",
            "0.35422915416916617",
            "0.37559589292262563",
            "0.38660692058750307",
            "0.38295766067621084",
            "0.37737730607593134",
            "0.37759336099585067",
            "0.38316373728029607",
            "0.380702368451756",
            "0.3824309392265193",
            "0.3796023564064801",
            "0.38771429999500173",
            "0.3858774857787598",
            "0.3786015617987614",
            "0.37331419124684595",
            "0.36800302571860827",
            "0.35964983713355053",
            "0.35756764207790165",
            "0.351660544842363",
            "0.343755830006343",
            "0.3326429311145234",
            "0.3268258671779676",
            "0.31922821024617437",
            "0.31284232231458214",
            "0.3080831696748652",
            "0.30294521593163437",
            "0.30225129297231523",
            "0.30225129297231523",
            "0.30225129297231523"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.0025,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-reqrate+/client_logs/8000_ml.json"
    },
    {
        "num_requests": "6580",
        "input_tokens": "397043",
        "output_tokens": "1156961",
        "mean_ttft": "178.39",
        "median_ttft": "176.08",
        "p99_ttft": "356.21",
        "hit_ratios": [
            "0.028225806451612902",
            "0.05838967424708052",
            "0.07949977668602054",
            "0.11890034364261166",
            "0.13438290694405397",
            "0.16934306569343066",
            "0.20485519591141396",
            "0.24282229311315445",
            "0.25077805077805077",
            "0.2611590255711908",
            "0.28392261507671784",
            "0.2898123007909338",
            "0.30729386892177585",
            "0.3153136004568383",
            "0.33275170127377424",
            "0.34767451073607475",
            "0.35596972293630397",
            "0.3620643964489202",
            "0.36707152496626183",
            "0.3730350309096262",
            "0.3782587037139536",
            "0.3808592717856576",
            "0.39075821015991524",
            "0.39655833573003546",
            "0.4027950167792948",
            "0.40961546836214774",
            "0.4092016685251723",
            "0.4141590117199872",
            "0.4178502806766378",
            "0.4224626107158413",
            "0.4314560820171791",
            "0.42795080871541225",
            "0.4238274227815001",
            "0.42870629700726925",
            "0.430640567238349",
            "0.428185488659304",
            "0.4317393920293383",
            "0.43793943041610806",
            "0.4396315327067968",
            "0.44212085000259765",
            "0.44284994964753266",
            "0.4428420768645916",
            "0.44634920634920633",
            "0.4453880143606737",
            "0.4493228922651316",
            "0.45371696393698724",
            "0.4560934182590233",
            "0.45812696054152213",
            "0.46022120595523497",
            "0.46127160832582026",
            "0.460694558590241",
            "0.4638101614223016",
            "0.46617184231112085",
            "0.4655370832669393",
            "0.46843882438066364",
            "0.4707675209645371",
            "0.47096816497819743",
            "0.46985932741423486",
            "0.4701651317878691",
            "0.46981475999813044",
            "0.4706986187590365",
            "0.46970110757093003",
            "0.46768129184954377",
            "0.466927679692694",
            "0.4677367762947453",
            "0.4665638379149789",
            "0.4665638379149789"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8003  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.02,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 2,
        "result_file": "lmsys-reqrate+/client_logs/8003_ml.json"
    },
    {
        "num_requests": "4114",
        "input_tokens": "278111",
        "output_tokens": "720394",
        "mean_ttft": "176.87",
        "median_ttft": "157.85",
        "p99_ttft": "391.55",
        "hit_ratios": [
            "0.016243654822335026",
            "0.030973451327433628",
            "0.03784056508577195",
            "0.0548102721349176",
            "0.06309562931317779",
            "0.09467803587180242",
            "0.13062213843253434",
            "0.24840107282855373",
            "0.2880297146716191",
            "0.30979228486646876",
            "0.3319294551197683",
            "0.35455680399500616",
            "0.3736145169200587",
            "0.3913421418636995",
            "0.41938526845373786",
            "0.42758571631811065",
            "0.443503003477711",
            "0.4469696969696969",
            "0.4500748342954886",
            "0.4528437355761834",
            "0.4463252522354516",
            "0.45681144020896974",
            "0.45055037391815805",
            "0.45627075755179497",
            "0.4614808434141043",
            "0.4647092647164522",
            "0.4673016091321689",
            "0.4656797208725991",
            "0.4590907648869008",
            "0.45610311307985724",
            "0.44908319894881454",
            "0.4420884699057288",
            "0.4385730528709494",
            "0.43641906873614195",
            "0.43051049102314515",
            "0.4269920844327177",
            "0.4219558002521289",
            "0.4152643930693563",
            "0.406547604623549",
            "0.40603175370339045",
            "0.40603175370339045",
            "0.40603175370339045"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.005,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.5,
        "result_file": "lmsys-reqrate++/client_logs/8001_ml.json"
    },
    {
        "num_requests": "4002",
        "input_tokens": "288354",
        "output_tokens": "706994",
        "mean_ttft": "187.79",
        "median_ttft": "173.09",
        "p99_ttft": "429.37",
        "hit_ratios": [
            "0.01331967213114754",
            "0.05575539568345323",
            "0.053730017761989345",
            "0.05491990846681922",
            "0.06109324758842444",
            "0.06377079482439926",
            "0.12547017732401933",
            "0.20800172080017207",
            "0.24246231155778894",
            "0.2963019327347436",
            "0.3121118012422361",
            "0.32994235334011535",
            "0.35406268716310646",
            "0.3663575429253513",
            "0.3735868017753957",
            "0.37502851494182954",
            "0.3712737127371274",
            "0.37521803300684287",
            "0.37745764807716087",
            "0.37484716157205233",
            "0.3770917324791517",
            "0.3730300483294809",
            "0.37881965248651883",
            "0.37698748706369367",
            "0.36998474104658474",
            "0.36342683191998265",
            "0.3571158293041834",
            "0.34702099951163934",
            "0.3471457776379935",
            "0.34606878670022123",
            "0.3365740056188083",
            "0.32692990554648116",
            "0.3204503851068975",
            "0.31611357054888006",
            "0.31052750589527417",
            "0.30709653044518614",
            "0.2998016175797346",
            "0.2955610283517541",
            "0.29547228727556607",
            "0.29547228727556607",
            "0.29547228727556607"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.0025,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-reqrate++/client_logs/8000_ml.json"
    },
    {
        "num_requests": "5018",
        "input_tokens": "313802",
        "output_tokens": "871060",
        "mean_ttft": "168.71",
        "median_ttft": "150.83",
        "p99_ttft": "345.07",
        "hit_ratios": [
            "0.03929273084479371",
            "0.06158730158730158",
            "0.07107355864811132",
            "0.09492273730684327",
            "0.11990335246149199",
            "0.13344051446945338",
            "0.16786689843555996",
            "0.22926626480981088",
            "0.30238210986874087",
            "0.3323549965059399",
            "0.3581943081452405",
            "0.3748371689101173",
            "0.38290926548247733",
            "0.37775464167968076",
            "0.3955594047712778",
            "0.3975096482924343",
            "0.40695814449480144",
            "0.41352829145419917",
            "0.4175022789425707",
            "0.4209933490667239",
            "0.42370724755700323",
            "0.43571597074781787",
            "0.44730833406516196",
            "0.45219468006258745",
            "0.4585600504692059",
            "0.4669025504938817",
            "0.4739972337482711",
            "0.47661645727816876",
            "0.4784428100431144",
            "0.48107712482083503",
            "0.4804288926039085",
            "0.4799260506056676",
            "0.4789070629986392",
            "0.4815562395922693",
            "0.4828457838421518",
            "0.4874594415366033",
            "0.4861104744441898",
            "0.48356639445128097",
            "0.4812679492993026",
            "0.4804644496603868",
            "0.4826845963789543",
            "0.48167074421908307",
            "0.4834234165651645",
            "0.48379560406698574",
            "0.4808090052164364",
            "0.47699278945570284",
            "0.47221004261886806",
            "0.4682435317223124",
            "0.46530427037292243",
            "0.46530427037292243",
            "0.46530427037292243"
        ],
        "args": " --port 8002  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-reqrate++/client_logs/8002_ml.json"
    },
    {
        "num_requests": "6775",
        "input_tokens": "407329",
        "output_tokens": "1169296",
        "mean_ttft": "183.29",
        "median_ttft": "184.08",
        "p99_ttft": "352.79",
        "hit_ratios": [
            "0.027944111776447105",
            "0.060072815533980584",
            "0.08",
            "0.11764705882352941",
            "0.13602015113350127",
            "0.17641441871568395",
            "0.2088098263447692",
            "0.24388422035480858",
            "0.24991751897063672",
            "0.25540664026804755",
            "0.2797193361219809",
            "0.28890481308969307",
            "0.30360753431946363",
            "0.3131039814456899",
            "0.3311403508771929",
            "0.3475250676428457",
            "0.35524525599713574",
            "0.3621045621045621",
            "0.3663735189935264",
            "0.3733255337818076",
            "0.38016026526664837",
            "0.38252868700756176",
            "0.3886172304279881",
            "0.3971105408231157",
            "0.40247805413313836",
            "0.41160365058670156",
            "0.4116658468601411",
            "0.41599557871466936",
            "0.4240827916012853",
            "0.42886991606325886",
            "0.4339706994979023",
            "0.4311373276776248",
            "0.4320371145977642",
            "0.43667714525817813",
            "0.4374342164616728",
            "0.4375329467580391",
            "0.4401687620342055",
            "0.44538413115472",
            "0.44810622090562846",
            "0.4494524227709474",
            "0.45082848074375825",
            "0.4506109731756",
            "0.45448601186306103",
            "0.4534457478005865",
            "0.4560185185185186",
            "0.46067391538378727",
            "0.4605855382156228",
            "0.4640151126260241",
            "0.46461464373858774",
            "0.46495490592442845",
            "0.46528845606241803",
            "0.4656735751295336",
            "0.4663402471634024",
            "0.46855872859083125",
            "0.46967071057192367",
            "0.4747095352564102",
            "0.47406035798979956",
            "0.473896994199332",
            "0.4723480558701396",
            "0.4724334013227023",
            "0.4724559188206478",
            "0.47166156064155706",
            "0.47084715014349654",
            "0.46974536290913343",
            "0.47153745299465477",
            "0.47069526774418247",
            "0.46871958358606874",
            "0.46871958358606874"
        ],
        "args": " --port 8003  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.02,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 2,
        "result_file": "lmsys-reqrate++/client_logs/8003_ml.json"
    },
    {
        "num_requests": "4118",
        "input_tokens": "278277",
        "output_tokens": "720395",
        "mean_ttft": "171.93",
        "median_ttft": "150.52",
        "p99_ttft": "369.03",
        "hit_ratios": [
            "0.016243654822335026",
            "0.028535193405199746",
            "0.03733602421796166",
            "0.05469356089992243",
            "0.06148222000664673",
            "0.0867224880382775",
            "0.12377049180327869",
            "0.23576567317574512",
            "0.260942760942761",
            "0.27021813325419203",
            "0.28266950845877187",
            "0.3010815211071055",
            "0.324343363188085",
            "0.34512957998212695",
            "0.3649813038530321",
            "0.37004340469359237",
            "0.38253583818812603",
            "0.38538387018648596",
            "0.3922654994736552",
            "0.39467672528289865",
            "0.38747717965165057",
            "0.3944283547096953",
            "0.39033959632067666",
            "0.3968280055879695",
            "0.40601152468462864",
            "0.41026023970429015",
            "0.4084476843910807",
            "0.40300991982606343",
            "0.4019992741908879",
            "0.4005322048026675",
            "0.39281601145453987",
            "0.3841279420639711",
            "0.38126664693696366",
            "0.377167713314513",
            "0.3696061090990765",
            "0.3634994935807945",
            "0.35803325948268966",
            "0.34881206723467795",
            "0.34346405228758176",
            "0.3434158800110174",
            "0.3434158800110174",
            "0.3434158800110174"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.005,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.5,
        "result_file": "lmsys-reqrate++/client_logs/8001_lru.json"
    },
    {
        "num_requests": "4001",
        "input_tokens": "288345",
        "output_tokens": "707524",
        "mean_ttft": "184.97",
        "median_ttft": "169.21",
        "p99_ttft": "466.63",
        "hit_ratios": [
            "0.01331967213114754",
            "0.0545785324439054",
            "0.05288888888888889",
            "0.053919694072657745",
            "0.053432642487046635",
            "0.05643410852713178",
            "0.11602060178910271",
            "0.18440486533449174",
            "0.21797631862217437",
            "0.24949604589858893",
            "0.25960264900662255",
            "0.28465547191661844",
            "0.2974826033565289",
            "0.313795702977761",
            "0.3224808865217765",
            "0.33468370208787784",
            "0.3270918665886483",
            "0.32725521227551085",
            "0.32123826439989844",
            "0.3202099737532808",
            "0.31932630146308266",
            "0.3187412285436683",
            "0.3182707153885743",
            "0.3178814382896015",
            "0.31820287169986095",
            "0.31391643854059137",
            "0.3082361105087391",
            "0.30426747311827945",
            "0.3058637725763343",
            "0.3005203646465041",
            "0.2939563578201759",
            "0.2842832596058933",
            "0.28095953095953097",
            "0.27270231313061977",
            "0.2663844256283752",
            "0.2616126630628297",
            "0.25586293618359013",
            "0.2526520891967958",
            "0.2525502318392581",
            "0.2525502318392581",
            "0.2525502318392581"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.0025,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-reqrate++/client_logs/8000_lru.json"
    },
    {
        "num_requests": "5023",
        "input_tokens": "313881",
        "output_tokens": "869457",
        "mean_ttft": "169.12",
        "median_ttft": "149.78",
        "p99_ttft": "353.21",
        "hit_ratios": [
            "0.03933136676499509",
            "0.061626429479034316",
            "0.07114427860696518",
            "0.09221689413500554",
            "0.11855203619909502",
            "0.12951969778737182",
            "0.15708908406524466",
            "0.1977604056623706",
            "0.26144438935713105",
            "0.29188107489994286",
            "0.31492687846696926",
            "0.33100574389007775",
            "0.33999204929437493",
            "0.3428956834532375",
            "0.35076948264571056",
            "0.3531064864043749",
            "0.3654601861427094",
            "0.38162723016575983",
            "0.3786384837928795",
            "0.3781255220805257",
            "0.3786556666137818",
            "0.3771994314561583",
            "0.38449882914734373",
            "0.3892585551330797",
            "0.39979321753515296",
            "0.4068922886725389",
            "0.4084132249480552",
            "0.4132076779155983",
            "0.4188882207523217",
            "0.4206015472025165",
            "0.4224740263685521",
            "0.4219636363636362",
            "0.42268618286641846",
            "0.42354849863028265",
            "0.42445261141881047",
            "0.4267972712961342",
            "0.42855420524691346",
            "0.42482781394471164",
            "0.4236848688848961",
            "0.4211586019740441",
            "0.42370357765771893",
            "0.4245864350703061",
            "0.4239416932907349",
            "0.42349919617299925",
            "0.42261116548640293",
            "0.4215604975499434",
            "0.4177694456697544",
            "0.4151808820117434",
            "0.41068729126384246",
            "0.41068729126384246",
            "0.41068729126384246"
        ],
        "args": " --port 8002  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-reqrate++/client_logs/8002_lru.json"
    },
    {
        "num_requests": "6758",
        "input_tokens": "406972",
        "output_tokens": "1195231",
        "mean_ttft": "182.24",
        "median_ttft": "181.97",
        "p99_ttft": "345.63",
        "hit_ratios": [
            "0.02721774193548387",
            "0.05953827460510329",
            "0.07864164432529043",
            "0.11145725164416753",
            "0.13029960429621254",
            "0.1677917068466731",
            "0.192847740236946",
            "0.21858440575321728",
            "0.22156084656084654",
            "0.22482758620689652",
            "0.24553571428571427",
            "0.2501512035805008",
            "0.27070270270270264",
            "0.27246860282574564",
            "0.2883612160460514",
            "0.30765507784141327",
            "0.3198014018691589",
            "0.32728014690879415",
            "0.3311907139291064",
            "0.34076812977099236",
            "0.3458378194593983",
            "0.35193899075125745",
            "0.3572497806225159",
            "0.3623464944468907",
            "0.366872263289232",
            "0.377835443604313",
            "0.3822623517995021",
            "0.38715693031175247",
            "0.3939032828476974",
            "0.39968176435760805",
            "0.4014918513804928",
            "0.39687468013238253",
            "0.3924652523774689",
            "0.39395592056719386",
            "0.39838759689922476",
            "0.39880539382786806",
            "0.39997665392359993",
            "0.4057579086734837",
            "0.40862120675082475",
            "0.4116487789288663",
            "0.41344741385975314",
            "0.4138580068763018",
            "0.4180604424736107",
            "0.4166529149673496",
            "0.4211274386190138",
            "0.42491941758363894",
            "0.4256359015574429",
            "0.4283267429320589",
            "0.43020196789228377",
            "0.42981064637256267",
            "0.4331901202597453",
            "0.432961320898945",
            "0.43324565821627764",
            "0.43670863047591313",
            "0.43886682552290174",
            "0.4427087818404146",
            "0.44128997617369703",
            "0.44143519664636655",
            "0.4414877238473381",
            "0.44200098586398245",
            "0.4403024799599197",
            "0.43986856177441597",
            "0.43963480128893656",
            "0.43967536687472597",
            "0.4403001708893676",
            "0.4390415475928775",
            "0.4376933854866016",
            "0.4376933854866016"
        ],
        "args": " --port 8003  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.02,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 2,
        "result_file": "lmsys-reqrate++/client_logs/8003_lru.json"
    },
    {
        "num_requests": "5022",
        "input_tokens": "313879",
        "output_tokens": "869995",
        "mean_ttft": "171.42",
        "median_ttft": "152.58",
        "p99_ttft": "403.30",
        "hit_ratios": [
            "0.0394088669950739",
            "0.06158730158730158",
            "0.07051282051282051",
            "0.08694070571116769",
            "0.10588935157644258",
            "0.10929108485499463",
            "0.1314086610253858",
            "0.15272878190495953",
            "0.21243102888672508",
            "0.23271760425412819",
            "0.24910857002336168",
            "0.26636175541761953",
            "0.2753219296559677",
            "0.2695644629533229",
            "0.2736369366530098",
            "0.26803746524220695",
            "0.2700900300100034",
            "0.27821490041799857",
            "0.28389009234978907",
            "0.28108398175476257",
            "0.2796476399001986",
            "0.27957141508543376",
            "0.29135693864086215",
            "0.2947442302134511",
            "0.2932132746146586",
            "0.29664385073967753",
            "0.29460580912863055",
            "0.2945874001774622",
            "0.2950798884098401",
            "0.2983595560434199",
            "0.29817835937049625",
            "0.29637703153886474",
            "0.2970888811804573",
            "0.3013245033112582",
            "0.30112044817927164",
            "0.30333799909847914",
            "0.30356897420625817",
            "0.30300517670259725",
            "0.3024858585639669",
            "0.3021078748201738",
            "0.3040603577657891",
            "0.3039277670209823",
            "0.3066016161000152",
            "0.3041435843689174",
            "0.301835249252883",
            "0.29967163697044724",
            "0.29800010535002536",
            "0.29477063906821044",
            "0.29102193218514527",
            "0.29102193218514527",
            "0.29102193218514527"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 5750 ",
        "size": 5750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8001_ml.json"
    },
    {
        "num_requests": "5020",
        "input_tokens": "313814",
        "output_tokens": "871287",
        "mean_ttft": "170.78",
        "median_ttft": "152.70",
        "p99_ttft": "386.79",
        "hit_ratios": [
            "0.0394088669950739",
            "0.061121613106490225",
            "0.06854043392504931",
            "0.07581891792418109",
            "0.09458655562165377",
            "0.09750201450443191",
            "0.10439146800501883",
            "0.12068248023304204",
            "0.148328464784161",
            "0.17226420375034987",
            "0.17938271604938275",
            "0.19054894685146787",
            "0.19863540265231597",
            "0.19651223321186884",
            "0.19457370455083212",
            "0.19010683447973073",
            "0.1878040653115628",
            "0.19154167691172855",
            "0.18785632839224634",
            "0.18610142205527233",
            "0.18636386781404352",
            "0.1841782309072029",
            "0.18699115433701538",
            "0.18914446466986595",
            "0.18784421715184893",
            "0.1859815488661007",
            "0.18319817009773348",
            "0.18186608701379972",
            "0.17769358125318394",
            "0.18128099932643443",
            "0.17806951593314446",
            "0.1769284032682455",
            "0.18101032743575382",
            "0.18307684519590975",
            "0.18327310273619007",
            "0.18483502387343526",
            "0.18320698105861075",
            "0.18200991720702742",
            "0.18035454683533325",
            "0.1807384833747314",
            "0.18570239714210335",
            "0.18367387266332066",
            "0.18507992217601965",
            "0.1834838322904569",
            "0.1815697279847394",
            "0.18024686921681024",
            "0.17984460694698368",
            "0.17651175095151145",
            "0.17476937579960955",
            "0.17476937579960955",
            "0.17476937579960955"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 3750 ",
        "size": 3750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_ml.json"
    },
    {
        "num_requests": "5037",
        "input_tokens": "314275",
        "output_tokens": "871761",
        "mean_ttft": "168.64",
        "median_ttft": "149.21",
        "p99_ttft": "403.83",
        "hit_ratios": [
            "0.03685258964143426",
            "0.061862244897959176",
            "0.07007007007007007",
            "0.06599552572706935",
            "0.07272727272727272",
            "0.07323026851098453",
            "0.07021063189568705",
            "0.07672903090182889",
            "0.10668210387032749",
            "0.11621621621621622",
            "0.11480324797001873",
            "0.12537412703691386",
            "0.1307880567792462",
            "0.12790389541559932",
            "0.12271077047196452",
            "0.11777877295118676",
            "0.1266539353430637",
            "0.13470721286755463",
            "0.13546165518851405",
            "0.13485420427813333",
            "0.1348461137193531",
            "0.13038219641993226",
            "0.13036990141991497",
            "0.12930011862396204",
            "0.13237736460485278",
            "0.13181852666717248",
            "0.13553754418538225",
            "0.13648097826086958",
            "0.13758334154432295",
            "0.13959077828025684",
            "0.13711315569363128",
            "0.13647153029999717",
            "0.1414138633485658",
            "0.13897914264752126",
            "0.13735829830594828",
            "0.13756678895920027",
            "0.13689470553242117",
            "0.13565116279069767",
            "0.13454374074240313",
            "0.13423834331294177",
            "0.13615349052242254",
            "0.1361534999795442",
            "0.13454818266174406",
            "0.13675478719280565",
            "0.13644302692030225",
            "0.1363890754421312",
            "0.13454122098522883",
            "0.13192332177972696",
            "0.13041967156138676",
            "0.13033891242447393",
            "0.13033891242447393"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 4000 ",
        "size": 4000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_lru.json"
    },
    {
        "num_requests": "5030",
        "input_tokens": "314006",
        "output_tokens": "871786",
        "mean_ttft": "169.37",
        "median_ttft": "151.61",
        "p99_ttft": "384.86",
        "hit_ratios": [
            "0.03933136676499509",
            "0.06163934426229509",
            "0.06986027944111775",
            "0.09097688292319164",
            "0.11151515151515153",
            "0.11266846361185984",
            "0.11203007518796991",
            "0.13085690164626423",
            "0.1741219350563287",
            "0.1952544311034877",
            "0.20610016317308902",
            "0.22252070740989482",
            "0.23290640394088669",
            "0.2262487757100881",
            "0.22320486815415821",
            "0.22035045498984732",
            "0.232144079983565",
            "0.2416703407444731",
            "0.24318168545231555",
            "0.23897464167585442",
            "0.242239932885906",
            "0.2373485736615865",
            "0.23936533989878261",
            "0.24038667179947812",
            "0.2442651155169589",
            "0.24804187521491616",
            "0.25127780577352243",
            "0.25618900873138156",
            "0.25707391246859707",
            "0.2599923503537961",
            "0.26001329064217954",
            "0.2570659877918245",
            "0.2611041229909154",
            "0.26020245919016316",
            "0.25757575757575746",
            "0.25699942556007876",
            "0.2565475469412476",
            "0.25408463986797103",
            "0.25276647958372134",
            "0.2506111402130259",
            "0.25267251822413017",
            "0.25191739193351664",
            "0.2499251242936725",
            "0.25039188024139825",
            "0.24821387416455404",
            "0.2477150487080152",
            "0.2430218279786669",
            "0.24005004021088375",
            "0.23692021285937584",
            "0.23692021285937584",
            "0.23692021285937584"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 6000 ",
        "size": 6000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8001_lru.json"
    },
    {
        "num_requests": "4955",
        "input_tokens": "309965",
        "output_tokens": "859922",
        "mean_ttft": "170.09",
        "median_ttft": "151.85",
        "p99_ttft": "386.05",
        "hit_ratios": [
            "0.03933136676499509",
            "0.06158730158730158",
            "0.06986027944111775",
            "0.08483954260420509",
            "0.106184012066365",
            "0.10522044901271299",
            "0.10612968591691994",
            "0.11769616026711184",
            "0.15219917012448134",
            "0.18285551276565398",
            "0.19269061121613104",
            "0.21261421885446846",
            "0.22388790907309425",
            "0.2176413341590728",
            "0.21574955623688885",
            "0.21550689862027594",
            "0.2290643753409711",
            "0.2374787909256583",
            "0.23946539045173343",
            "0.2366776315789474",
            "0.2403088641936662",
            "0.23876186785506687",
            "0.24159035270650106",
            "0.2425027610228528",
            "0.2464823098820659",
            "0.24962869873186339",
            "0.25119832774714385",
            "0.25595340071954775",
            "0.2549188473004306",
            "0.25802646261756734",
            "0.2584005072004348",
            "0.25608909459068563",
            "0.26149817533498626",
            "0.2591649424372646",
            "0.255727649923975",
            "0.25472144119037554",
            "0.25423444172544507",
            "0.2527488018043418",
            "0.2514003220173709",
            "0.24912854030501094",
            "0.25108813350601933",
            "0.25054700078437847",
            "0.2482055985325784",
            "0.2488547825065581",
            "0.2463551831018253",
            "0.24606819502502483",
            "0.24242924485041914",
            "0.23950068950695777",
            "0.23826399772047302",
            "0.23826399772047302"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 6000 ",
        "size": 6000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8001_lru.json"
    },
    {
        "num_requests": "4957",
        "input_tokens": "309974",
        "output_tokens": "859467",
        "mean_ttft": "168.07",
        "median_ttft": "149.94",
        "p99_ttft": "372.54",
        "hit_ratios": [
            "0.03944773175542406",
            "0.061626429479034316",
            "0.0707070707070707",
            "0.06599552572706935",
            "0.07299270072992702",
            "0.07313109425785481",
            "0.07045797684952188",
            "0.07684188304834283",
            "0.10968921389396709",
            "0.11986202931876977",
            "0.11753590325018898",
            "0.1287028725314183",
            "0.1318887899475611",
            "0.12899767732713951",
            "0.12442885117493471",
            "0.11972150749205386",
            "0.1282704489121454",
            "0.13640687424694017",
            "0.13821712268314207",
            "0.13708914965797228",
            "0.13662068601025315",
            "0.13337916809900308",
            "0.13235766389870166",
            "0.13121392263289391",
            "0.13501709859503108",
            "0.13461538461538458",
            "0.13742988271290157",
            "0.13862863488097715",
            "0.13936920967256428",
            "0.1376858227685179",
            "0.13497287743036507",
            "0.13462268836366822",
            "0.1398160906611175",
            "0.13750668806848582",
            "0.13607265535547",
            "0.13569402966346275",
            "0.13516528825398366",
            "0.13392095535968151",
            "0.13278643572048807",
            "0.13283775759308533",
            "0.13488143348942622",
            "0.13486910558954504",
            "0.13344709897610915",
            "0.13559021274078742",
            "0.13460907810721653",
            "0.13473428668967866",
            "0.13316420066295065",
            "0.13088391714290862",
            "0.13019172191363554",
            "0.13019172191363554"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 4000 ",
        "size": 4000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_lru.json"
    },
    {
        "num_requests": "5027",
        "input_tokens": "313986",
        "output_tokens": "872265",
        "mean_ttft": "163.92",
        "median_ttft": "146.58",
        "p99_ttft": "357.63",
        "hit_ratios": [
            "0.03681592039800995",
            "0.060082872928176795",
            "0.07063572149344097",
            "0.09375000000000001",
            "0.11978221415607984",
            "0.13052858683926644",
            "0.16141047926496152",
            "0.20307628351694038",
            "0.2722411278561011",
            "0.30635918937805734",
            "0.3256299938537185",
            "0.3439947780678851",
            "0.35084013442150747",
            "0.34294621979734996",
            "0.35643330179754024",
            "0.3545296167247387",
            "0.3523295340931814",
            "0.3585427290041162",
            "0.3656201925816194",
            "0.3664253150978815",
            "0.36390472312703587",
            "0.3666902571361171",
            "0.37571047957371234",
            "0.38333470699744515",
            "0.3871727440436473",
            "0.3926668871009223",
            "0.39527015363369594",
            "0.39893023561068464",
            "0.40048751147551376",
            "0.40260649797509224",
            "0.40527936900889505",
            "0.40056771206525943",
            "0.3999840463718791",
            "0.40079125088196765",
            "0.40224162456467366",
            "0.4072098976109215",
            "0.40658684010939766",
            "0.4063694267515924",
            "0.40570738336101464",
            "0.40225041001473977",
            "0.4050740470988103",
            "0.4048936044566051",
            "0.4051933743636501",
            "0.40289903738526966",
            "0.4002558713332723",
            "0.39762994882844055",
            "0.3939457604566065",
            "0.38830730409875186",
            "0.384399946333937",
            "0.3841744464743643",
            "0.3841744464743643"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 7750 ",
        "size": 7750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_ml.json"
    },
    {
        "num_requests": "5028",
        "input_tokens": "313990",
        "output_tokens": "871462",
        "mean_ttft": "162.57",
        "median_ttft": "143.51",
        "p99_ttft": "341.68",
        "hit_ratios": [
            "0.03681592039800995",
            "0.060082872928176795",
            "0.06979062811565304",
            "0.09371513573819264",
            "0.12012102874432676",
            "0.1343042071197411",
            "0.16786689843555996",
            "0.22926626480981088",
            "0.30238210986874087",
            "0.33240145373217783",
            "0.3576516826332597",
            "0.37461840383776707",
            "0.3829092654824772",
            "0.3788862908114662",
            "0.39604350567465313",
            "0.3975824655938251",
            "0.4070519229487436",
            "0.41358972783682496",
            "0.4173214895797745",
            "0.4210469856254023",
            "0.4237581433224756",
            "0.4357631516867186",
            "0.44644820760941273",
            "0.45366739588062893",
            "0.459318306761957",
            "0.46711374774310027",
            "0.47408278294546835",
            "0.4771651991063214",
            "0.4790022503248708",
            "0.48160229247324937",
            "0.4809371487853376",
            "0.4804127124255131",
            "0.4793245117916977",
            "0.4818897240579124",
            "0.48316977428851815",
            "0.4869051572804478",
            "0.4862477689808247",
            "0.4838392198089785",
            "0.48153185242751984",
            "0.4807185131346693",
            "0.4828891948809331",
            "0.48191178791226136",
            "0.48359595036918623",
            "0.485027588141775",
            "0.48158438282549487",
            "0.47812112832851533",
            "0.473341273733623",
            "0.46939471440750224",
            "0.4664183486854248",
            "0.4659738518270199",
            "0.4659738518270199"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8001_ml.json"
    },
    {
        "num_requests": "4956",
        "input_tokens": "309970",
        "output_tokens": "860185",
        "mean_ttft": "165.88",
        "median_ttft": "144.52",
        "p99_ttft": "372.77",
        "hit_ratios": [
            "0.0394088669950739",
            "0.06158730158730158",
            "0.06979062811565304",
            "0.08796466691203533",
            "0.11386288130474176",
            "0.12459807073954983",
            "0.15669232679413955",
            "0.19912700062357097",
            "0.26916221033868093",
            "0.3037037037037037",
            "0.3233849177106362",
            "0.3407827319306661",
            "0.3490158425348056",
            "0.3409543604399411",
            "0.3522557278954413",
            "0.34632541133455214",
            "0.34906352062920754",
            "0.3555323462554525",
            "0.3627713520597118",
            "0.36374363100026824",
            "0.3613599348534202",
            "0.3645199339466856",
            "0.3774190710767065",
            "0.37937991518096104",
            "0.3836220472440945",
            "0.39017479300827956",
            "0.3927952892275718",
            "0.39659599683961017",
            "0.3975700518431347",
            "0.40003060443764343",
            "0.40268262365218394",
            "0.39830555401738743",
            "0.398015259030038",
            "0.3990066644705167",
            "0.40000492222878514",
            "0.40586361042419633",
            "0.4063648897058823",
            "0.4040742071691672",
            "0.40282785283002476",
            "0.3991099782717701",
            "0.40291626896285615",
            "0.40158570101034063",
            "0.4020465045244549",
            "0.3998462490390564",
            "0.3968640668217536",
            "0.39404883833755594",
            "0.3910452483915199",
            "0.38672277567846103",
            "0.385100061471211",
            "0.385100061471211"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 7750 ",
        "size": 7750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_ml.json"
    },
    {
        "num_requests": "4960",
        "input_tokens": "310086",
        "output_tokens": "859507",
        "mean_ttft": "163.36",
        "median_ttft": "146.19",
        "p99_ttft": "318.91",
        "hit_ratios": [
            "0.0394088669950739",
            "0.06158730158730158",
            "0.07051282051282051",
            "0.09537892791127542",
            "0.12008469449485783",
            "0.13344051446945338",
            "0.16786689843555996",
            "0.22926626480981088",
            "0.30238210986874087",
            "0.3323549965059399",
            "0.3581943081452405",
            "0.37483716891011726",
            "0.3829092654824773",
            "0.3787996882307093",
            "0.39596469104665827",
            "0.39685085289400795",
            "0.40695814449480144",
            "0.41352829145419917",
            "0.4175260668907755",
            "0.4209933490667239",
            "0.42370724755700323",
            "0.43533852323661243",
            "0.4459792363188457",
            "0.4536317008603574",
            "0.4594201188087651",
            "0.46715382344257456",
            "0.4736314278797939",
            "0.4766318280418063",
            "0.4784883167940141",
            "0.48112114188117605",
            "0.4804704390187656",
            "0.4799657817760361",
            "0.47966590169183965",
            "0.48227397744190154",
            "0.4835439931279911",
            "0.48726832625358923",
            "0.48687826325913713",
            "0.48424774008771143",
            "0.4819253692666494",
            "0.4810968009970918",
            "0.4833012658227848",
            "0.48276269883507783",
            "0.4843851040359085",
            "0.48482754757147395",
            "0.48165087263546885",
            "0.4781460048165055",
            "0.47194644480178977",
            "0.46894192113591654",
            "0.4678491862383292",
            "0.4678491862383292"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8001_ml.json"
    },
    {
        "num_requests": "5041",
        "input_tokens": "314520",
        "output_tokens": "873779",
        "mean_ttft": "164.10",
        "median_ttft": "143.34",
        "p99_ttft": "366.12",
        "hit_ratios": [
            "0.03685258964143426",
            "0.06254158349966733",
            "0.06993006993006994",
            "0.08568249258160238",
            "0.10752360645750837",
            "0.1180158081221041",
            "0.127927474187862",
            "0.15459757910384372",
            "0.21592978970028148",
            "0.2518253400143164",
            "0.2614321608040201",
            "0.28412132024977693",
            "0.29334647609659925",
            "0.2995379420650435",
            "0.29720986655883536",
            "0.29597250242845397",
            "0.30535811919081457",
            "0.31839919456330223",
            "0.3168507802910748",
            "0.31260328302302515",
            "0.31385598993816155",
            "0.31049739874556326",
            "0.3181549109785529",
            "0.32395450269391945",
            "0.33306228655065867",
            "0.33579406364749076",
            "0.33666570771001153",
            "0.3424756034925526",
            "0.34492332099418294",
            "0.34752358865203165",
            "0.34707438811714475",
            "0.3436304541663071",
            "0.3453669941826482",
            "0.3493571088417377",
            "0.3501254930082467",
            "0.35169596434761086",
            "0.350283299721502",
            "0.3476142512473356",
            "0.34578741315712064",
            "0.3425944042261789",
            "0.34397328034498803",
            "0.34485381800238507",
            "0.3468906630742716",
            "0.3477201870615745",
            "0.3448177242220867",
            "0.34369732159580446",
            "0.33903872121455425",
            "0.33440326298989187",
            "0.3303192696423273",
            "0.32949204470285137",
            "0.32949204470285137"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 8000 ",
        "size": 8000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_lru.json"
    },
    {
        "num_requests": "5044",
        "input_tokens": "314836",
        "output_tokens": "873001",
        "mean_ttft": "162.65",
        "median_ttft": "145.67",
        "p99_ttft": "344.78",
        "hit_ratios": [
            "0.039525691699604744",
            "0.06460481099656357",
            "0.06986027944111775",
            "0.08389261744966442",
            "0.10814950980392156",
            "0.12339961863252517",
            "0.15084361621757741",
            "0.19584569732937684",
            "0.2641102257636122",
            "0.2944300890037324",
            "0.31911413111866105",
            "0.33201312662668325",
            "0.3410829607550919",
            "0.3428340951868782",
            "0.3496400523560209",
            "0.3564766059876635",
            "0.36168307967770813",
            "0.37691281986157843",
            "0.3766501650165016",
            "0.37545991749358903",
            "0.3761977870718407",
            "0.37583529874213834",
            "0.38440316350928816",
            "0.3915337051930643",
            "0.40121981373114646",
            "0.40710530385031696",
            "0.41178183936503304",
            "0.4154128186503407",
            "0.4210105052526263",
            "0.42306706809301126",
            "0.42387842387842384",
            "0.4240237443985334",
            "0.4259512958872703",
            "0.42508238545763793",
            "0.42568109492639256",
            "0.4273995283728864",
            "0.42750090942160784",
            "0.4238484310242748",
            "0.42231967475218135",
            "0.42111381632339717",
            "0.4224574911774142",
            "0.4240472133327792",
            "0.42389623948440985",
            "0.4245364891518738",
            "0.42364456090324076",
            "0.4226069825152968",
            "0.41723084848038855",
            "0.4164381106032088",
            "0.4121384943056803",
            "0.41154555838678497",
            "0.41154555838678497"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8001_lru.json"
    },
    {
        "num_requests": "5016",
        "input_tokens": "313751",
        "output_tokens": "868184",
        "mean_ttft": "168.29",
        "median_ttft": "148.90",
        "p99_ttft": "358.77",
        "hit_ratios": [
            "0.03944773175542406",
            "0.061626429479034316",
            "0.06986027944111775",
            "0.09097688292319164",
            "0.11327649208282582",
            "0.12246003793010024",
            "0.13294651866801208",
            "0.15819567979669633",
            "0.21925754060324826",
            "0.25401606425702816",
            "0.2610229276895944",
            "0.2824427480916031",
            "0.292025755324418",
            "0.29657454610499956",
            "0.2950472466601499",
            "0.291216675477683",
            "0.30487302676733014",
            "0.31747037576832904",
            "0.31573687613896895",
            "0.31203195207189216",
            "0.31305677086078754",
            "0.3106268364348677",
            "0.3202329634045676",
            "0.32458748007410276",
            "0.33388232387697114",
            "0.3373787345881807",
            "0.3398975402390727",
            "0.3454124637280641",
            "0.34749858347498586",
            "0.35028049366885716",
            "0.3508570044212949",
            "0.34732624978226795",
            "0.3490068454718887",
            "0.3504937844384699",
            "0.35155542913294197",
            "0.3528618182726659",
            "0.3521408756482933",
            "0.34923592113951507",
            "0.3464894342194956",
            "0.3433920272304772",
            "0.3457131316567104",
            "0.34624927632123076",
            "0.3483594295402414",
            "0.34847505435740733",
            "0.34569368816627044",
            "0.34420549131859446",
            "0.34015655433464415",
            "0.33553981479829437",
            "0.33167542487565693",
            "0.33167542487565693",
            "0.33167542487565693"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 8000 ",
        "size": 8000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_lru.json"
    },
    {
        "num_requests": "5017",
        "input_tokens": "313757",
        "output_tokens": "869016",
        "mean_ttft": "164.44",
        "median_ttft": "146.31",
        "p99_ttft": "340.68",
        "hit_ratios": [
            "0.039525691699604744",
            "0.06012439530062197",
            "0.06986027944111775",
            "0.08475836431226766",
            "0.10736009732360097",
            "0.12339961863252517",
            "0.15069182389937105",
            "0.1960950764006791",
            "0.2636815920398009",
            "0.29968634160250923",
            "0.3236177132849637",
            "0.33790871554514007",
            "0.34199861619057026",
            "0.34362176628010704",
            "0.3524423061241132",
            "0.3570191945803538",
            "0.3630358494460883",
            "0.37866413421968975",
            "0.37921711531679797",
            "0.37868707030383675",
            "0.3799020898036532",
            "0.376063361689645",
            "0.38325849903784476",
            "0.38966408268733854",
            "0.40143266475644696",
            "0.4075141177826438",
            "0.4119051926904288",
            "0.41631727266478796",
            "0.42196665893348356",
            "0.4233072170201923",
            "0.4251052315093205",
            "0.42482024733966056",
            "0.42533476312243945",
            "0.4257960776043863",
            "0.4269170659219595",
            "0.4290658294811262",
            "0.4298180601047171",
            "0.4260224960830626",
            "0.4243032833126481",
            "0.42302273663220413",
            "0.4239536898147171",
            "0.42466739322654284",
            "0.42494605776273336",
            "0.4249164659258684",
            "0.4247570507578496",
            "0.42328329189179087",
            "0.41778520442450556",
            "0.4165941655865486",
            "0.4120675812476001",
            "0.4120675812476001",
            "0.4120675812476001"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8001_lru.json"
    },
    {
        "num_requests": "5058",
        "input_tokens": "317588",
        "output_tokens": "874890",
        "mean_ttft": "145.43",
        "median_ttft": "123.27",
        "p99_ttft": "365.51",
        "hit_ratios": [
            "0.03681592039800995",
            "0.06277056277056275",
            "0.0706713780918728",
            "0.08463832960477255",
            "0.11387678904791536",
            "0.12958500669344042",
            "0.16050295857988164",
            "0.2142565359477124",
            "0.2791935483870967",
            "0.32596915381408914",
            "0.3605633802816901",
            "0.38123709098815084",
            "0.38507290867229466",
            "0.3749458921305515",
            "0.37069372345445967",
            "0.3643343473851948",
            "0.3673252178540544",
            "0.37585086159318093",
            "0.37072643495079355",
            "0.365225734235915",
            "0.3617505691879585",
            "0.3544012762762763",
            "0.3517689403915372",
            "0.3471336268982263",
            "0.35021560172481386",
            "0.35707775874011166",
            "0.3517070313845731",
            "0.3536221427868692",
            "0.34787415503190355",
            "0.3437670941469642",
            "0.33964432441750236",
            "0.33348003080646954",
            "0.3351430472388557",
            "0.3326263697419584",
            "0.3330310309328889",
            "0.33616467526322025",
            "0.33540957984738434",
            "0.32966001296466013",
            "0.3286734407697452",
            "0.32362183422471025",
            "0.32207608255766895",
            "0.3178914997634443",
            "0.3131524405316499",
            "0.3128717315677253",
            "0.3115245988619939",
            "0.31083194047554863",
            "0.3091722202735882",
            "0.3059897610921501",
            "0.30171733619835817",
            "0.29997997797577336",
            "0.29997997797577336"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 3750 ",
        "size": 3750,
        "num_prompts": 30000,
        "use_oracle": 3,
        "use_token_id": 1,
        "algorithm": "ml-true",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_ml-true.json"
    },
    {
        "num_requests": "5058",
        "input_tokens": "317588",
        "output_tokens": "875854",
        "mean_ttft": "141.47",
        "median_ttft": "120.39",
        "p99_ttft": "323.85",
        "hit_ratios": [
            "0.03948667324777888",
            "0.06146059291395516",
            "0.0680306905370844",
            "0.08640595903165735",
            "0.1160547604231487",
            "0.1344762925261184",
            "0.16736504806507269",
            "0.23447712418300654",
            "0.30081037277147493",
            "0.3473669584549118",
            "0.38315815204106574",
            "0.4142841613218829",
            "0.4341903300076747",
            "0.4417799324733789",
            "0.4681453515809344",
            "0.47827031725336805",
            "0.4867939591510877",
            "0.49739375728214874",
            "0.502275571737399",
            "0.5008261819732424",
            "0.49800151783455593",
            "0.5061496573091728",
            "0.5129730912273026",
            "0.5197893524232698",
            "0.5276460676358791",
            "0.5339795211893741",
            "0.537181254307374",
            "0.5360868709402268",
            "0.5378074223936269",
            "0.5299835956011907",
            "0.5235223160434258",
            "0.5183128024637041",
            "0.519891500904159",
            "0.5189953141532725",
            "0.5166789125642909",
            "0.5209461856889414",
            "0.5224109513780788",
            "0.5209129725258757",
            "0.5193116387397294",
            "0.515390522841902",
            "0.516363930579716",
            "0.5121254506412402",
            "0.5066354855882576",
            "0.5048520090496044",
            "0.5020944994237837",
            "0.5009967851434111",
            "0.49578099613913085",
            "0.49182959105267626",
            "0.48618358136335393",
            "0.48399432245136487",
            "0.48399432245136487"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 5750 ",
        "size": 5750,
        "num_prompts": 30000,
        "use_oracle": 3,
        "use_token_id": 1,
        "algorithm": "ml-true",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_ml-true.json"
    },
    {
        "num_requests": "5052",
        "input_tokens": "317364",
        "output_tokens": "874887",
        "mean_ttft": "139.39",
        "median_ttft": "120.43",
        "p99_ttft": "275.40",
        "hit_ratios": [
            "0.036926147704590816",
            "0.06277056277056275",
            "0.0706713780918728",
            "0.08640595903165735",
            "0.11729931549471062",
            "0.135475234270415",
            "0.16909046093172295",
            "0.23590686274509806",
            "0.30184705119896305",
            "0.3483395859385855",
            "0.3841359080909313",
            "0.41534449032818943",
            "0.4342747726184777",
            "0.44264565838455533",
            "0.46893188610980013",
            "0.4792119368390554",
            "0.4878600412425996",
            "0.49892684123382597",
            "0.5063996814380795",
            "0.5173498214380896",
            "0.5232481659499114",
            "0.5384940381184865",
            "0.5511959622558701",
            "0.5620113570899513",
            "0.5709638223650687",
            "0.5829913527773706",
            "0.5943607597118333",
            "0.5948872772618382",
            "0.5944537443542528",
            "0.5983469567595491",
            "0.5970869602688958",
            "0.5974036689677933",
            "0.5972336746907831",
            "0.6023549582713495",
            "0.604458255848096",
            "0.6069518716577539",
            "0.6101408193123625",
            "0.6093809300560351",
            "0.6083353117648325",
            "0.6067497253259807",
            "0.6077678535343326",
            "0.6063635111469665",
            "0.6070885883604313",
            "0.6086997123753313",
            "0.6054424253492829",
            "0.6021617351335822",
            "0.5962673277698242",
            "0.594780383795309",
            "0.5894530398779688",
            "0.5885854341736692",
            "0.5885854341736692"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 7750 ",
        "size": 7750,
        "num_prompts": 30000,
        "use_oracle": 3,
        "use_token_id": 1,
        "algorithm": "ml-true",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_ml-true.json"
    },
    {
        "num_requests": "5064",
        "input_tokens": "318052",
        "output_tokens": "879647",
        "mean_ttft": "137.31",
        "median_ttft": "117.61",
        "p99_ttft": "277.63",
        "hit_ratios": [
            "0.036926147704590816",
            "0.06163886874546772",
            "0.0706713780918728",
            "0.08650260999254288",
            "0.1131957473420888",
            "0.13515687851971037",
            "0.16909046093172295",
            "0.23590686274509806",
            "0.3056451612903226",
            "0.3490343198554954",
            "0.38521781693587864",
            "0.41711055549516257",
            "0.4371642363775902",
            "0.44446368279802617",
            "0.47075493977800525",
            "0.48095031145878603",
            "0.49253139458030404",
            "0.5031699585466959",
            "0.5108345120226309",
            "0.5215823523173189",
            "0.5270692610142151",
            "0.5421551683871269",
            "0.5550793720208159",
            "0.5660694518469925",
            "0.5749286858661246",
            "0.5882288749045139",
            "0.5981928124785264",
            "0.6037429332640195",
            "0.6066743887549695",
            "0.6104968214274951",
            "0.6119860268010534",
            "0.6172694493006992",
            "0.6171337916446322",
            "0.6233288267988583",
            "0.6257028112449797",
            "0.6298058801356953",
            "0.6330827409207564",
            "0.6320742154556347",
            "0.6326285284962968",
            "0.6327830334508128",
            "0.634947470112305",
            "0.6340417197140336",
            "0.635274781327338",
            "0.6356846935552786",
            "0.6333212209302321",
            "0.630893466492773",
            "0.6267567708423809",
            "0.6262139219015277",
            "0.6222377995860868",
            "0.6198111644856713",
            "0.6198111644856713"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 3,
        "use_token_id": 1,
        "algorithm": "ml-true",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_ml-true.json"
    }
]