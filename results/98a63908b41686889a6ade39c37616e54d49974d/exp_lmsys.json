[
    {
        "num_requests": "4895",
        "input_tokens": "303149",
        "output_tokens": "864137",
        "mean_ttft": "168.39",
        "median_ttft": "150.82",
        "p99_ttft": "376.22",
        "hit_ratios": [
            "0.03681592039800995",
            "0.060082872928176795",
            "0.06996501749125437",
            "0.08668154761904762",
            "0.11433756805807621",
            "0.12834941050375132",
            "0.16314874596473802",
            "0.2259405528996051",
            "0.2868255544521681",
            "0.32106310403638433",
            "0.34829644367072865",
            "0.36885873727978996",
            "0.3782499029879705",
            "0.37519664394336655",
            "0.38679846938775514",
            "0.39071297989031084",
            "0.3967837437760733",
            "0.407662505380973",
            "0.4108888383723574",
            "0.41862955032119925",
            "0.4170751633986929",
            "0.42718122406144166",
            "0.44065033486076843",
            "0.44993412384716736",
            "0.459296875",
            "0.4721459180309856",
            "0.4787223116162827",
            "0.47881819085157834",
            "0.48017268947873365",
            "0.48539277872651865",
            "0.4844530415451684",
            "0.4866247705911794",
            "0.48916697796040326",
            "0.488063592679685",
            "0.48597181982517385",
            "0.48864911317466747",
            "0.4868863793500805",
            "0.48511777542801854",
            "0.4863942639944711",
            "0.48306137488156636",
            "0.4870633365981063",
            "0.4848527042348774",
            "0.48375576704051876",
            "0.4816208448360623",
            "0.4781467723753025",
            "0.4747368801764981",
            "0.470776183162986",
            "0.4650673110113909",
            "0.4617723941159384",
            "0.4617723941159384"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-reqrate+/client_logs/8000_ml.json"
    },
    {
        "num_requests": "9577",
        "input_tokens": "555488",
        "output_tokens": "1674314",
        "mean_ttft": "211.72",
        "median_ttft": "210.96",
        "p99_ttft": "428.21",
        "hit_ratios": [
            "0.04407443682664055",
            "0.09681029658645775",
            "0.12111425111021397",
            "0.16833181955797757",
            "0.18246146070255245",
            "0.20108932461873638",
            "0.2106399685904986",
            "0.21686532645436754",
            "0.23785725441199437",
            "0.25520091194072386",
            "0.26915193440942864",
            "0.27100646352723917",
            "0.27037444933920707",
            "0.27340053486936844",
            "0.27932692307692303",
            "0.27707612456747405",
            "0.27510008006405123",
            "0.27383751801562617",
            "0.2783781874690965",
            "0.2892092039143084",
            "0.28986993015954376",
            "0.2960490380530436",
            "0.3035267349260523",
            "0.31088935190262096",
            "0.31690177502472555",
            "0.3198636318058759",
            "0.3243882426758049",
            "0.32568721268411677",
            "0.32597983816283177",
            "0.324279548328029",
            "0.32623214134753575",
            "0.32987066310819135",
            "0.32817374610031197",
            "0.3277346780449961",
            "0.32993184748572485",
            "0.3319336702014092",
            "0.3353439559290122",
            "0.3376312147703109",
            "0.3401013568742848",
            "0.3416562228863395",
            "0.3452447770502027",
            "0.34523267461979784",
            "0.34665065463811845",
            "0.3479807610211458",
            "0.35113762486126515",
            "0.35251465176502644",
            "0.35090329436769385",
            "0.3530937192054353",
            "0.357523016773868",
            "0.3572503639369339",
            "0.35836930455635474",
            "0.3612314175348237",
            "0.36556251865114875",
            "0.3664431030628212",
            "0.36738201207420773",
            "0.3672605550156569",
            "0.36886989068946435",
            "0.36915927156495754",
            "0.3711830881443935",
            "0.37195109629180545",
            "0.37338645418326677",
            "0.37168956932546593",
            "0.3715666376727552",
            "0.3714882126510522",
            "0.369379559979639",
            "0.3698500482518",
            "0.3702036992818175",
            "0.37032807685336216",
            "0.37151111983021506",
            "0.37150745251533296",
            "0.37215650591446753",
            "0.37113141393028104",
            "0.37304651895063046",
            "0.37197341997420347",
            "0.3726398461291872",
            "0.37161339301247875",
            "0.3720868561445106",
            "0.37093028620641916",
            "0.3724384083725291",
            "0.3720124336302928",
            "0.3715172999736324",
            "0.37218181029371344",
            "0.37008266818700103",
            "0.3702961918194639",
            "0.3708585180210431",
            "0.3716172346627249",
            "0.37288089692899296",
            "0.372264719208934",
            "0.3753229550551482",
            "0.3771979653489632",
            "0.37770763312928896",
            "0.3783135555974131",
            "0.3782147886454035",
            "0.3786357849378121",
            "0.3757768097404398",
            "0.37480866736821955",
            "0.3743720092125203",
            "0.3743720092125203"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8003  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.04,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 4,
        "result_file": "lmsys-reqrate+/client_logs/8003_ml.json"
    },
    {
        "num_requests": "8299",
        "input_tokens": "482816",
        "output_tokens": "1429271",
        "mean_ttft": "204.67",
        "median_ttft": "206.86",
        "p99_ttft": "376.82",
        "hit_ratios": [
            "0.03898635477582846",
            "0.07096004770423374",
            "0.09637526652452026",
            "0.15533088235294118",
            "0.16573886639676114",
            "0.1962888441761681",
            "0.2224852071005917",
            "0.23349805859512882",
            "0.2417207792207792",
            "0.2504424778761062",
            "0.2628729865328756",
            "0.27688706846108835",
            "0.2847826086956522",
            "0.28575745366639804",
            "0.29422649888971136",
            "0.2995869510241928",
            "0.30711465510567465",
            "0.31019769591807705",
            "0.3109203946479253",
            "0.31974317817014447",
            "0.3245271507016473",
            "0.33294910956140855",
            "0.34114696903619707",
            "0.3424556988570829",
            "0.3443271767810026",
            "0.34893493696565714",
            "0.3498357578601595",
            "0.3561959914943672",
            "0.3616315630787785",
            "0.3580907356722235",
            "0.35788630904723767",
            "0.3593166251556662",
            "0.3668069753457607",
            "0.3702748828933512",
            "0.3686157097569566",
            "0.36930226201052413",
            "0.37066471585807864",
            "0.3753311839627158",
            "0.3764057060110299",
            "0.3776198828670808",
            "0.3794462965647195",
            "0.380991293076728",
            "0.3859485803466308",
            "0.3894850349797486",
            "0.3889104303993796",
            "0.392911277283751",
            "0.39317641872198694",
            "0.396674809667244",
            "0.39724753580063255",
            "0.39964949016751655",
            "0.3999246470601273",
            "0.40262638958112135",
            "0.40589526100350276",
            "0.4067000561108919",
            "0.4080855397148677",
            "0.410456611978652",
            "0.41097646236308566",
            "0.4106809434896926",
            "0.4115829682058197",
            "0.4123415140505673",
            "0.4141309296185014",
            "0.4162013680676494",
            "0.41679794672094883",
            "0.41654342038870434",
            "0.41547676254547955",
            "0.41572235564726184",
            "0.41310049467149174",
            "0.4132926649284204",
            "0.4119518807734143",
            "0.41111518299580957",
            "0.41154769940817265",
            "0.4110327729139228",
            "0.41227855833842403",
            "0.41177002486624975",
            "0.41317683927330784",
            "0.4154027025850182",
            "0.4155517438536307",
            "0.41432438944876754",
            "0.4153957778118852",
            "0.41649951916472033",
            "0.4179163057600692",
            "0.41642008863420316",
            "0.4159863049776138",
            "0.4155748680652189",
            "0.4155748680652189"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8002  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.03,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 3,
        "result_file": "lmsys-reqrate+/client_logs/8002_ml.json"
    },
    {
        "num_requests": "6582",
        "input_tokens": "395237",
        "output_tokens": "1172334",
        "mean_ttft": "193.41",
        "median_ttft": "195.96",
        "p99_ttft": "370.03",
        "hit_ratios": [
            "0.028225806451612902",
            "0.05838967424708052",
            "0.07949977668602054",
            "0.1181129476584022",
            "0.13510457885811192",
            "0.16707496325330723",
            "0.21127057830308152",
            "0.24313651748777737",
            "0.25077805077805077",
            "0.2611590255711908",
            "0.2840363053924186",
            "0.29059018724816305",
            "0.3079775399936434",
            "0.31540877510231274",
            "0.33397229241090876",
            "0.34926151172893144",
            "0.3557032590051458",
            "0.3640217247317526",
            "0.3692920625191542",
            "0.3753005336304463",
            "0.38214285714285723",
            "0.38569617578702736",
            "0.39260119107701624",
            "0.39894937917860557",
            "0.4046014941106375",
            "0.41283529054903145",
            "0.41226554787759134",
            "0.4169200995299973",
            "0.42154250328391824",
            "0.4249440150256448",
            "0.4332060412151236",
            "0.4296911325141149",
            "0.4269455252918288",
            "0.43091899336421685",
            "0.43343466875357434",
            "0.428962472406181",
            "0.432102280816652",
            "0.4382842056558069",
            "0.4410526594477245",
            "0.44266019517736366",
            "0.4471006741461232",
            "0.44618627641015707",
            "0.45066164329403013",
            "0.4492434225473713",
            "0.45341642261026593",
            "0.4581663058157731",
            "0.4598132015412967",
            "0.4610196430026897",
            "0.46207048193975253",
            "0.4628521468816786",
            "0.4614917672054025",
            "0.46424146030219526",
            "0.4660539525477592",
            "0.4651675874119704",
            "0.468675519237317",
            "0.4676956745196214",
            "0.466732821447163",
            "0.4650927811903579",
            "0.46519637271319797",
            "0.4650949268596328",
            "0.46444922415117534",
            "0.46321268758941897",
            "0.46054036174467394",
            "0.4586446064962648",
            "0.4571344685848503",
            "0.4556869509289443",
            "0.4556869509289443"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.02,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 2,
        "result_file": "lmsys-reqrate+/client_logs/8001_ml.json"
    },
    {
        "num_requests": "4909",
        "input_tokens": "304274",
        "output_tokens": "866848",
        "mean_ttft": "170.44",
        "median_ttft": "150.80",
        "p99_ttft": "370.24",
        "hit_ratios": [
            "0.03929273084479371",
            "0.06158730158730158",
            "0.07051282051282051",
            "0.09492273730684327",
            "0.11990335246149199",
            "0.13344051446945338",
            "0.16786689843555996",
            "0.21430056121388488",
            "0.2689506785832506",
            "0.30514496873223423",
            "0.32777915941308133",
            "0.34697450486924175",
            "0.35492957746478876",
            "0.35679887925750814",
            "0.364875637755102",
            "0.3703839122486288",
            "0.37528573349468863",
            "0.3897773403862714",
            "0.38836165255441263",
            "0.38954017450885925",
            "0.3863868464052288",
            "0.3835328912846443",
            "0.39364689364689354",
            "0.4026787554090253",
            "0.4107400898262058",
            "0.4172037498169035",
            "0.42115747896273403",
            "0.42419525765001986",
            "0.428361310951239",
            "0.42878464818763323",
            "0.42760233242884355",
            "0.4275362318840579",
            "0.4298885592880622",
            "0.4285786892328022",
            "0.42966872320919736",
            "0.4298373420593785",
            "0.43105197620255487",
            "0.4290987665436211",
            "0.42591870341480315",
            "0.42623917760316826",
            "0.4293150964580994",
            "0.42821890547263675",
            "0.4270650263620386",
            "0.4253480102889998",
            "0.42334053834358654",
            "0.42284598133545526",
            "0.41751994915613294",
            "0.41472379933387393",
            "0.411398451093446",
            "0.411398451093446"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-reqrate+/client_logs/8000_lru.json"
    },
    {
        "num_requests": "6615",
        "input_tokens": "398563",
        "output_tokens": "1164458",
        "mean_ttft": "185.96",
        "median_ttft": "186.02",
        "p99_ttft": "364.80",
        "hit_ratios": [
            "0.028028028028028028",
            "0.060072815533980584",
            "0.08104517271922054",
            "0.11877789220734636",
            "0.13411896745230079",
            "0.1704878048780488",
            "0.20608251807741385",
            "0.22610809799887788",
            "0.22627857260319023",
            "0.2281340003031681",
            "0.24909066415196013",
            "0.25384707145413343",
            "0.2713983050847458",
            "0.27628291370363245",
            "0.3012490173814306",
            "0.3145417063114494",
            "0.32379723237972324",
            "0.33459319673761684",
            "0.33931203931203924",
            "0.3464325693748895",
            "0.3523255813953488",
            "0.3574950951800201",
            "0.36641068112232084",
            "0.3719143213908365",
            "0.3780465372942149",
            "0.38704478132078746",
            "0.38961414525324284",
            "0.393758168640342",
            "0.3992302177276328",
            "0.40399709302325565",
            "0.4088342283041745",
            "0.4036353916065222",
            "0.3997257232416899",
            "0.40234781785477597",
            "0.40771049281687566",
            "0.4060647379653782",
            "0.4060456579098312",
            "0.41346548750102663",
            "0.41460147354320154",
            "0.4199025965570226",
            "0.42380976320949165",
            "0.42304032789284923",
            "0.4265386150703266",
            "0.42600082731994304",
            "0.42905202183357477",
            "0.43223022206800843",
            "0.43335736397947516",
            "0.43664207098396485",
            "0.4387444885139626",
            "0.43855218855218864",
            "0.44046342397548843",
            "0.44173184357541906",
            "0.44364800698600987",
            "0.44292997238547055",
            "0.44828299188448756",
            "0.4491792238403906",
            "0.4480364219973143",
            "0.44768911283182283",
            "0.44840495566236777",
            "0.4485781916715982",
            "0.4475981190644498",
            "0.44763031737362713",
            "0.4478868597282358",
            "0.4479886585149745",
            "0.4471907823911084",
            "0.44579196183524217",
            "0.4447645254679395",
            "0.4447645254679395"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.02,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 2,
        "result_file": "lmsys-reqrate+/client_logs/8001_lru.json"
    },
    {
        "num_requests": "8306",
        "input_tokens": "484485",
        "output_tokens": "1428493",
        "mean_ttft": "203.89",
        "median_ttft": "205.34",
        "p99_ttft": "390.07",
        "hit_ratios": [
            "0.03887269193391643",
            "0.0803727431566686",
            "0.09637526652452026",
            "0.15533088235294118",
            "0.16573886639676114",
            "0.19357014388489208",
            "0.21920792079207918",
            "0.23236587510993836",
            "0.2391233766233766",
            "0.2323682256867112",
            "0.23554264589384735",
            "0.2502937720329025",
            "0.2573784722222222",
            "0.25789897363654657",
            "0.2672630696114062",
            "0.2699831365935919",
            "0.2810844499844188",
            "0.28405776481468303",
            "0.28356387306753456",
            "0.2926360315323976",
            "0.29675613170227005",
            "0.30478328440683816",
            "0.3072981958903363",
            "0.31112856768787645",
            "0.31718575631530893",
            "0.3220028004442084",
            "0.32273345527883307",
            "0.3298656655660591",
            "0.33458225667527997",
            "0.33251732293265845",
            "0.33226401475659645",
            "0.3351391378907163",
            "0.34207457014936604",
            "0.34496067579376644",
            "0.342416434294589",
            "0.3441445140100585",
            "0.3464739961377106",
            "0.34971209213051824",
            "0.35200247409927327",
            "0.35203186777252593",
            "0.3541055079203604",
            "0.3582001016891701",
            "0.3631321548591569",
            "0.36601875263379685",
            "0.3667270844122217",
            "0.37208890238963155",
            "0.37216431637032504",
            "0.3753176129752322",
            "0.37623462541930686",
            "0.3805142453711085",
            "0.38343680709534367",
            "0.3860180398433951",
            "0.38854335771963483",
            "0.3896889221370239",
            "0.3917750239098142",
            "0.39377430370501965",
            "0.3932412269653342",
            "0.39410993022415725",
            "0.39487457475045795",
            "0.3958818958818959",
            "0.3982176702143169",
            "0.40040241448692154",
            "0.40039914519347947",
            "0.4008725578808316",
            "0.39954099371435425",
            "0.39919001012487343",
            "0.3977619363395225",
            "0.3971199476354116",
            "0.39546375050627786",
            "0.39657834009707965",
            "0.39712205379280047",
            "0.39733337458043966",
            "0.3979465554384196",
            "0.3975981579858237",
            "0.39878805793674255",
            "0.40063210392020415",
            "0.4015917924096936",
            "0.40028625278104507",
            "0.4003771476463193",
            "0.40282797191265995",
            "0.4034281388558452",
            "0.40248551897582713",
            "0.40193510169156854",
            "0.40102767109281817",
            "0.40102767109281817"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8002  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.03,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 3,
        "result_file": "lmsys-reqrate+/client_logs/8002_lru.json"
    },
    {
        "num_requests": "9571",
        "input_tokens": "557844",
        "output_tokens": "1676559",
        "mean_ttft": "219.37",
        "median_ttft": "219.10",
        "p99_ttft": "448.19",
        "hit_ratios": [
            "0.04407443682664055",
            "0.0975473801560758",
            "0.11933656957928802",
            "0.16980568011958147",
            "0.1813627254509018",
            "0.20166631061738943",
            "0.21200311769290728",
            "0.22060627299807253",
            "0.2173230817511376",
            "0.2267806267806268",
            "0.2338129496402878",
            "0.23431156478366777",
            "0.23529411764705885",
            "0.23994238090338516",
            "0.24366509297620198",
            "0.24263176144244109",
            "0.24177763516765605",
            "0.2425415622864951",
            "0.24684799546678",
            "0.26146055437100213",
            "0.26494023904382474",
            "0.2718376223269301",
            "0.28197823485841267",
            "0.284020390070922",
            "0.2922682569575225",
            "0.29498941425546926",
            "0.3002482597478459",
            "0.3001751810993797",
            "0.30217331999636254",
            "0.30189673340358264",
            "0.30317223759846706",
            "0.30484873601326146",
            "0.3044247787610619",
            "0.30416764406912183",
            "0.30807199851549444",
            "0.3097072419106317",
            "0.3121220644072563",
            "0.31539718194813143",
            "0.3190620471611118",
            "0.32128176080271886",
            "0.3241899968543567",
            "0.3229080428050164",
            "0.32670345560244335",
            "0.32770620039111925",
            "0.3306010161974005",
            "0.33106638398634314",
            "0.3289907519099316",
            "0.3307950845499421",
            "0.33410678769952556",
            "0.3351073132948553",
            "0.33629133934632904",
            "0.3418269572006528",
            "0.3449035940509059",
            "0.3448470737165719",
            "0.3464743660970242",
            "0.3470683186458423",
            "0.34792611864880546",
            "0.34782331434401825",
            "0.349262868565717",
            "0.3508108991380365",
            "0.3521483746379142",
            "0.35080006337135594",
            "0.3500868580797531",
            "0.34978524165151087",
            "0.347574180312298",
            "0.347465576107755",
            "0.3477551927958641",
            "0.34870490963635015",
            "0.34805330076862273",
            "0.3480659088906509",
            "0.34843271840799434",
            "0.3471022379429968",
            "0.3485202752354864",
            "0.34844990610483284",
            "0.3479325441868004",
            "0.3482623631860666",
            "0.348719803724207",
            "0.3485250120138272",
            "0.34986550100874214",
            "0.349372227652056",
            "0.3502370858383677",
            "0.3504914112397559",
            "0.35032771804749013",
            "0.35060192845324334",
            "0.3511654188444693",
            "0.35213389121338884",
            "0.35279808677827096",
            "0.35203079159152667",
            "0.35404630009122495",
            "0.3561574170665551",
            "0.35622803743129633",
            "0.35719363274010485",
            "0.3568213642728543",
            "0.35626826471349804",
            "0.35393539720339473",
            "0.3529816846276516",
            "0.352842486421243",
            "0.352842486421243"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8003  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.04,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 4,
        "result_file": "lmsys-reqrate+/client_logs/8003_lru.json"
    },
    {
        "num_requests": "3815",
        "input_tokens": "273288",
        "output_tokens": "687031",
        "mean_ttft": "175.22",
        "median_ttft": "158.52",
        "p99_ttft": "410.19",
        "hit_ratios": [
            "0.01331967213114754",
            "0.054334554334554336",
            "0.05427782888684452",
            "0.05521235521235521",
            "0.061284046692607",
            "0.0637904468412943",
            "0.12654486835034928",
            "0.20977816067197932",
            "0.25296512657107456",
            "0.30275643922277445",
            "0.31532226939405633",
            "0.33647692825867287",
            "0.3585130702713447",
            "0.3793072014585232",
            "0.38542449286250935",
            "0.3860380504813158",
            "0.3814469659244504",
            "0.380876281795179",
            "0.3856598672892602",
            "0.38305045338293414",
            "0.3846492677017949",
            "0.38484405966412844",
            "0.3896226885311269",
            "0.3880841888154502",
            "0.3808138233582523",
            "0.37579839235281326",
            "0.3700226339173442",
            "0.36413965893477734",
            "0.35841591915076965",
            "0.3515388114008489",
            "0.34317670074932627",
            "0.3329790625996386",
            "0.3292913982569155",
            "0.32265057026612415",
            "0.31590364566470247",
            "0.31314655850077033",
            "0.3070032823092733",
            "0.30567685589519644",
            "0.30567685589519644"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.0025,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-reqrate+/client_logs/8000_ml.json"
    },
    {
        "num_requests": "3944",
        "input_tokens": "266221",
        "output_tokens": "699923",
        "mean_ttft": "167.99",
        "median_ttft": "144.88",
        "p99_ttft": "374.25",
        "hit_ratios": [
            "0.016243654822335026",
            "0.028827674567584886",
            "0.03784056508577195",
            "0.05549088086922778",
            "0.06210561275323812",
            "0.08508088675853806",
            "0.12233169129720854",
            "0.24587118084227905",
            "0.2772649572649573",
            "0.3041067146282974",
            "0.332019445539351",
            "0.3570536828963795",
            "0.3691699604743083",
            "0.3913386517050934",
            "0.4140965670340126",
            "0.42563189747241015",
            "0.4372974003686519",
            "0.44380538764011973",
            "0.4446005837206789",
            "0.4454037845103919",
            "0.44329896907216504",
            "0.444897410626288",
            "0.4448391052475792",
            "0.4546393390530665",
            "0.45732261976955735",
            "0.4646530493988122",
            "0.4639986139986141",
            "0.46176966013805865",
            "0.4616439666996268",
            "0.45821191642383285",
            "0.45095376071471693",
            "0.4480538570084666",
            "0.4444700793078587",
            "0.44066606761765686",
            "0.4343945905992498",
            "0.43270973243790634",
            "0.42704903155547486",
            "0.4202305125872004",
            "0.41497241139334884",
            "0.41497241139334884",
            "0.41497241139334884"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.005,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.5,
        "result_file": "lmsys-reqrate+/client_logs/8001_ml.json"
    },
    {
        "num_requests": "4020",
        "input_tokens": "272121",
        "output_tokens": "715227",
        "mean_ttft": "171.40",
        "median_ttft": "150.42",
        "p99_ttft": "397.23",
        "hit_ratios": [
            "0.01331967213114754",
            "0.028827674567584886",
            "0.03799392097264438",
            "0.06050096339113681",
            "0.06361829025844931",
            "0.08508088675853806",
            "0.12233169129720854",
            "0.23162675474814204",
            "0.2505982905982906",
            "0.26184052757793763",
            "0.2794639337800552",
            "0.3014413800930655",
            "0.3212450592885376",
            "0.34838257210484785",
            "0.37715415019762843",
            "0.38272043163424674",
            "0.39013538422424204",
            "0.3937437643054169",
            "0.39828126689006593",
            "0.39796498114766804",
            "0.3957650856952951",
            "0.39890857040615496",
            "0.3983856653847779",
            "0.40723426171704774",
            "0.4151794172255694",
            "0.419084882078035",
            "0.4137883488452258",
            "0.40808726601634593",
            "0.4081288392374041",
            "0.4025986078886311",
            "0.3965366661647343",
            "0.3870231019236964",
            "0.3852694473170172",
            "0.3785380329796467",
            "0.3707414282594454",
            "0.36472748562912505",
            "0.35829499043581664",
            "0.35124465677646466",
            "0.3452893937910097",
            "0.34500952660120177",
            "0.34500952660120177"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.005,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.5,
        "result_file": "lmsys-reqrate+/client_logs/8001_lru.json"
    },
    {
        "num_requests": "3900",
        "input_tokens": "278653",
        "output_tokens": "703398",
        "mean_ttft": "174.94",
        "median_ttft": "160.54",
        "p99_ttft": "418.29",
        "hit_ratios": [
            "0.01331967213114754",
            "0.054334554334554336",
            "0.05427782888684452",
            "0.055404881828748545",
            "0.06134371957156767",
            "0.0637904468412943",
            "0.12573885008060184",
            "0.19750161533491278",
            "0.23260754115772703",
            "0.27248079530049707",
            "0.28521806252412196",
            "0.3108790838666218",
            "0.3216380081502833",
            "0.33679795769511306",
            "0.3459387261040154",
            "0.3565527173501099",
            "0.3485807782599416",
            "0.3497802636835796",
            "0.342774637503072",
            "0.3420134852359916",
            "0.33955511507543223",
            "0.3381662668196516",
            "0.34042765289338583",
            "0.34205221956593074",
            "0.3398062606511795",
            "0.3347529442440572",
            "0.3281079721686646",
            "0.3262204978984804",
            "0.32416549130230365",
            "0.3183230990827079",
            "0.31223005648049024",
            "0.3016114751195325",
            "0.2958706125258087",
            "0.2896360785883452",
            "0.28334036545389635",
            "0.27775856105153934",
            "0.2718511946645456",
            "0.2683212996389892",
            "0.2683212996389892",
            "0.2683212996389892"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.0025,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-reqrate+/client_logs/8000_lru.json"
    },
    {
        "num_requests": "3843",
        "input_tokens": "275851",
        "output_tokens": "694466",
        "mean_ttft": "179.31",
        "median_ttft": "165.20",
        "p99_ttft": "436.75",
        "hit_ratios": [
            "0.01331967213114754",
            "0.05538832028898254",
            "0.05370616955170883",
            "0.05464272067252579",
            "0.06113256113256113",
            "0.06377079482439926",
            "0.12547017732401933",
            "0.20864702086470208",
            "0.24246231155778894",
            "0.2958795803557853",
            "0.30943738656987296",
            "0.3314498813425246",
            "0.35422915416916617",
            "0.37559589292262563",
            "0.38660692058750307",
            "0.38295766067621084",
            "0.37737730607593134",
            "0.37759336099585067",
            "0.38316373728029607",
            "0.380702368451756",
            "0.3824309392265193",
            "0.3796023564064801",
            "0.38771429999500173",
            "0.3858774857787598",
            "0.3786015617987614",
            "0.37331419124684595",
            "0.36800302571860827",
            "0.35964983713355053",
            "0.35756764207790165",
            "0.351660544842363",
            "0.343755830006343",
            "0.3326429311145234",
            "0.3268258671779676",
            "0.31922821024617437",
            "0.31284232231458214",
            "0.3080831696748652",
            "0.30294521593163437",
            "0.30225129297231523",
            "0.30225129297231523",
            "0.30225129297231523"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.0025,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-reqrate+/client_logs/8000_ml.json"
    },
    {
        "num_requests": "6580",
        "input_tokens": "397043",
        "output_tokens": "1156961",
        "mean_ttft": "178.39",
        "median_ttft": "176.08",
        "p99_ttft": "356.21",
        "hit_ratios": [
            "0.028225806451612902",
            "0.05838967424708052",
            "0.07949977668602054",
            "0.11890034364261166",
            "0.13438290694405397",
            "0.16934306569343066",
            "0.20485519591141396",
            "0.24282229311315445",
            "0.25077805077805077",
            "0.2611590255711908",
            "0.28392261507671784",
            "0.2898123007909338",
            "0.30729386892177585",
            "0.3153136004568383",
            "0.33275170127377424",
            "0.34767451073607475",
            "0.35596972293630397",
            "0.3620643964489202",
            "0.36707152496626183",
            "0.3730350309096262",
            "0.3782587037139536",
            "0.3808592717856576",
            "0.39075821015991524",
            "0.39655833573003546",
            "0.4027950167792948",
            "0.40961546836214774",
            "0.4092016685251723",
            "0.4141590117199872",
            "0.4178502806766378",
            "0.4224626107158413",
            "0.4314560820171791",
            "0.42795080871541225",
            "0.4238274227815001",
            "0.42870629700726925",
            "0.430640567238349",
            "0.428185488659304",
            "0.4317393920293383",
            "0.43793943041610806",
            "0.4396315327067968",
            "0.44212085000259765",
            "0.44284994964753266",
            "0.4428420768645916",
            "0.44634920634920633",
            "0.4453880143606737",
            "0.4493228922651316",
            "0.45371696393698724",
            "0.4560934182590233",
            "0.45812696054152213",
            "0.46022120595523497",
            "0.46127160832582026",
            "0.460694558590241",
            "0.4638101614223016",
            "0.46617184231112085",
            "0.4655370832669393",
            "0.46843882438066364",
            "0.4707675209645371",
            "0.47096816497819743",
            "0.46985932741423486",
            "0.4701651317878691",
            "0.46981475999813044",
            "0.4706986187590365",
            "0.46970110757093003",
            "0.46768129184954377",
            "0.466927679692694",
            "0.4677367762947453",
            "0.4665638379149789",
            "0.4665638379149789"
        ],
        "args": "--num-gpu-blocks-override 10000  --port 8003  --eviction_algorithm ml --max-num-batched-tokens 2048 ",
        "size": 10000,
        "num_prompts": 50000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.02,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m/lmsys-chat-1m_epoch4_metric_0_6818.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 2,
        "result_file": "lmsys-reqrate+/client_logs/8003_ml.json"
    },
    {
        "num_requests": "4114",
        "input_tokens": "278111",
        "output_tokens": "720394",
        "mean_ttft": "176.87",
        "median_ttft": "157.85",
        "p99_ttft": "391.55",
        "hit_ratios": [
            "0.016243654822335026",
            "0.030973451327433628",
            "0.03784056508577195",
            "0.0548102721349176",
            "0.06309562931317779",
            "0.09467803587180242",
            "0.13062213843253434",
            "0.24840107282855373",
            "0.2880297146716191",
            "0.30979228486646876",
            "0.3319294551197683",
            "0.35455680399500616",
            "0.3736145169200587",
            "0.3913421418636995",
            "0.41938526845373786",
            "0.42758571631811065",
            "0.443503003477711",
            "0.4469696969696969",
            "0.4500748342954886",
            "0.4528437355761834",
            "0.4463252522354516",
            "0.45681144020896974",
            "0.45055037391815805",
            "0.45627075755179497",
            "0.4614808434141043",
            "0.4647092647164522",
            "0.4673016091321689",
            "0.4656797208725991",
            "0.4590907648869008",
            "0.45610311307985724",
            "0.44908319894881454",
            "0.4420884699057288",
            "0.4385730528709494",
            "0.43641906873614195",
            "0.43051049102314515",
            "0.4269920844327177",
            "0.4219558002521289",
            "0.4152643930693563",
            "0.406547604623549",
            "0.40603175370339045",
            "0.40603175370339045",
            "0.40603175370339045"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.005,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.5,
        "result_file": "lmsys-reqrate++/client_logs/8001_ml.json"
    },
    {
        "num_requests": "4002",
        "input_tokens": "288354",
        "output_tokens": "706994",
        "mean_ttft": "187.79",
        "median_ttft": "173.09",
        "p99_ttft": "429.37",
        "hit_ratios": [
            "0.01331967213114754",
            "0.05575539568345323",
            "0.053730017761989345",
            "0.05491990846681922",
            "0.06109324758842444",
            "0.06377079482439926",
            "0.12547017732401933",
            "0.20800172080017207",
            "0.24246231155778894",
            "0.2963019327347436",
            "0.3121118012422361",
            "0.32994235334011535",
            "0.35406268716310646",
            "0.3663575429253513",
            "0.3735868017753957",
            "0.37502851494182954",
            "0.3712737127371274",
            "0.37521803300684287",
            "0.37745764807716087",
            "0.37484716157205233",
            "0.3770917324791517",
            "0.3730300483294809",
            "0.37881965248651883",
            "0.37698748706369367",
            "0.36998474104658474",
            "0.36342683191998265",
            "0.3571158293041834",
            "0.34702099951163934",
            "0.3471457776379935",
            "0.34606878670022123",
            "0.3365740056188083",
            "0.32692990554648116",
            "0.3204503851068975",
            "0.31611357054888006",
            "0.31052750589527417",
            "0.30709653044518614",
            "0.2998016175797346",
            "0.2955610283517541",
            "0.29547228727556607",
            "0.29547228727556607",
            "0.29547228727556607"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.0025,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-reqrate++/client_logs/8000_ml.json"
    },
    {
        "num_requests": "5018",
        "input_tokens": "313802",
        "output_tokens": "871060",
        "mean_ttft": "168.71",
        "median_ttft": "150.83",
        "p99_ttft": "345.07",
        "hit_ratios": [
            "0.03929273084479371",
            "0.06158730158730158",
            "0.07107355864811132",
            "0.09492273730684327",
            "0.11990335246149199",
            "0.13344051446945338",
            "0.16786689843555996",
            "0.22926626480981088",
            "0.30238210986874087",
            "0.3323549965059399",
            "0.3581943081452405",
            "0.3748371689101173",
            "0.38290926548247733",
            "0.37775464167968076",
            "0.3955594047712778",
            "0.3975096482924343",
            "0.40695814449480144",
            "0.41352829145419917",
            "0.4175022789425707",
            "0.4209933490667239",
            "0.42370724755700323",
            "0.43571597074781787",
            "0.44730833406516196",
            "0.45219468006258745",
            "0.4585600504692059",
            "0.4669025504938817",
            "0.4739972337482711",
            "0.47661645727816876",
            "0.4784428100431144",
            "0.48107712482083503",
            "0.4804288926039085",
            "0.4799260506056676",
            "0.4789070629986392",
            "0.4815562395922693",
            "0.4828457838421518",
            "0.4874594415366033",
            "0.4861104744441898",
            "0.48356639445128097",
            "0.4812679492993026",
            "0.4804644496603868",
            "0.4826845963789543",
            "0.48167074421908307",
            "0.4834234165651645",
            "0.48379560406698574",
            "0.4808090052164364",
            "0.47699278945570284",
            "0.47221004261886806",
            "0.4682435317223124",
            "0.46530427037292243",
            "0.46530427037292243",
            "0.46530427037292243"
        ],
        "args": " --port 8002  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-reqrate++/client_logs/8002_ml.json"
    },
    {
        "num_requests": "6775",
        "input_tokens": "407329",
        "output_tokens": "1169296",
        "mean_ttft": "183.29",
        "median_ttft": "184.08",
        "p99_ttft": "352.79",
        "hit_ratios": [
            "0.027944111776447105",
            "0.060072815533980584",
            "0.08",
            "0.11764705882352941",
            "0.13602015113350127",
            "0.17641441871568395",
            "0.2088098263447692",
            "0.24388422035480858",
            "0.24991751897063672",
            "0.25540664026804755",
            "0.2797193361219809",
            "0.28890481308969307",
            "0.30360753431946363",
            "0.3131039814456899",
            "0.3311403508771929",
            "0.3475250676428457",
            "0.35524525599713574",
            "0.3621045621045621",
            "0.3663735189935264",
            "0.3733255337818076",
            "0.38016026526664837",
            "0.38252868700756176",
            "0.3886172304279881",
            "0.3971105408231157",
            "0.40247805413313836",
            "0.41160365058670156",
            "0.4116658468601411",
            "0.41599557871466936",
            "0.4240827916012853",
            "0.42886991606325886",
            "0.4339706994979023",
            "0.4311373276776248",
            "0.4320371145977642",
            "0.43667714525817813",
            "0.4374342164616728",
            "0.4375329467580391",
            "0.4401687620342055",
            "0.44538413115472",
            "0.44810622090562846",
            "0.4494524227709474",
            "0.45082848074375825",
            "0.4506109731756",
            "0.45448601186306103",
            "0.4534457478005865",
            "0.4560185185185186",
            "0.46067391538378727",
            "0.4605855382156228",
            "0.4640151126260241",
            "0.46461464373858774",
            "0.46495490592442845",
            "0.46528845606241803",
            "0.4656735751295336",
            "0.4663402471634024",
            "0.46855872859083125",
            "0.46967071057192367",
            "0.4747095352564102",
            "0.47406035798979956",
            "0.473896994199332",
            "0.4723480558701396",
            "0.4724334013227023",
            "0.4724559188206478",
            "0.47166156064155706",
            "0.47084715014349654",
            "0.46974536290913343",
            "0.47153745299465477",
            "0.47069526774418247",
            "0.46871958358606874",
            "0.46871958358606874"
        ],
        "args": " --port 8003  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.02,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 2,
        "result_file": "lmsys-reqrate++/client_logs/8003_ml.json"
    },
    {
        "num_requests": "4118",
        "input_tokens": "278277",
        "output_tokens": "720395",
        "mean_ttft": "171.93",
        "median_ttft": "150.52",
        "p99_ttft": "369.03",
        "hit_ratios": [
            "0.016243654822335026",
            "0.028535193405199746",
            "0.03733602421796166",
            "0.05469356089992243",
            "0.06148222000664673",
            "0.0867224880382775",
            "0.12377049180327869",
            "0.23576567317574512",
            "0.260942760942761",
            "0.27021813325419203",
            "0.28266950845877187",
            "0.3010815211071055",
            "0.324343363188085",
            "0.34512957998212695",
            "0.3649813038530321",
            "0.37004340469359237",
            "0.38253583818812603",
            "0.38538387018648596",
            "0.3922654994736552",
            "0.39467672528289865",
            "0.38747717965165057",
            "0.3944283547096953",
            "0.39033959632067666",
            "0.3968280055879695",
            "0.40601152468462864",
            "0.41026023970429015",
            "0.4084476843910807",
            "0.40300991982606343",
            "0.4019992741908879",
            "0.4005322048026675",
            "0.39281601145453987",
            "0.3841279420639711",
            "0.38126664693696366",
            "0.377167713314513",
            "0.3696061090990765",
            "0.3634994935807945",
            "0.35803325948268966",
            "0.34881206723467795",
            "0.34346405228758176",
            "0.3434158800110174",
            "0.3434158800110174",
            "0.3434158800110174"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.005,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.5,
        "result_file": "lmsys-reqrate++/client_logs/8001_lru.json"
    },
    {
        "num_requests": "4001",
        "input_tokens": "288345",
        "output_tokens": "707524",
        "mean_ttft": "184.97",
        "median_ttft": "169.21",
        "p99_ttft": "466.63",
        "hit_ratios": [
            "0.01331967213114754",
            "0.0545785324439054",
            "0.05288888888888889",
            "0.053919694072657745",
            "0.053432642487046635",
            "0.05643410852713178",
            "0.11602060178910271",
            "0.18440486533449174",
            "0.21797631862217437",
            "0.24949604589858893",
            "0.25960264900662255",
            "0.28465547191661844",
            "0.2974826033565289",
            "0.313795702977761",
            "0.3224808865217765",
            "0.33468370208787784",
            "0.3270918665886483",
            "0.32725521227551085",
            "0.32123826439989844",
            "0.3202099737532808",
            "0.31932630146308266",
            "0.3187412285436683",
            "0.3182707153885743",
            "0.3178814382896015",
            "0.31820287169986095",
            "0.31391643854059137",
            "0.3082361105087391",
            "0.30426747311827945",
            "0.3058637725763343",
            "0.3005203646465041",
            "0.2939563578201759",
            "0.2842832596058933",
            "0.28095953095953097",
            "0.27270231313061977",
            "0.2663844256283752",
            "0.2616126630628297",
            "0.25586293618359013",
            "0.2526520891967958",
            "0.2525502318392581",
            "0.2525502318392581",
            "0.2525502318392581"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.0025,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-reqrate++/client_logs/8000_lru.json"
    },
    {
        "num_requests": "5023",
        "input_tokens": "313881",
        "output_tokens": "869457",
        "mean_ttft": "169.12",
        "median_ttft": "149.78",
        "p99_ttft": "353.21",
        "hit_ratios": [
            "0.03933136676499509",
            "0.061626429479034316",
            "0.07114427860696518",
            "0.09221689413500554",
            "0.11855203619909502",
            "0.12951969778737182",
            "0.15708908406524466",
            "0.1977604056623706",
            "0.26144438935713105",
            "0.29188107489994286",
            "0.31492687846696926",
            "0.33100574389007775",
            "0.33999204929437493",
            "0.3428956834532375",
            "0.35076948264571056",
            "0.3531064864043749",
            "0.3654601861427094",
            "0.38162723016575983",
            "0.3786384837928795",
            "0.3781255220805257",
            "0.3786556666137818",
            "0.3771994314561583",
            "0.38449882914734373",
            "0.3892585551330797",
            "0.39979321753515296",
            "0.4068922886725389",
            "0.4084132249480552",
            "0.4132076779155983",
            "0.4188882207523217",
            "0.4206015472025165",
            "0.4224740263685521",
            "0.4219636363636362",
            "0.42268618286641846",
            "0.42354849863028265",
            "0.42445261141881047",
            "0.4267972712961342",
            "0.42855420524691346",
            "0.42482781394471164",
            "0.4236848688848961",
            "0.4211586019740441",
            "0.42370357765771893",
            "0.4245864350703061",
            "0.4239416932907349",
            "0.42349919617299925",
            "0.42261116548640293",
            "0.4215604975499434",
            "0.4177694456697544",
            "0.4151808820117434",
            "0.41068729126384246",
            "0.41068729126384246",
            "0.41068729126384246"
        ],
        "args": " --port 8002  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-reqrate++/client_logs/8002_lru.json"
    },
    {
        "num_requests": "6758",
        "input_tokens": "406972",
        "output_tokens": "1195231",
        "mean_ttft": "182.24",
        "median_ttft": "181.97",
        "p99_ttft": "345.63",
        "hit_ratios": [
            "0.02721774193548387",
            "0.05953827460510329",
            "0.07864164432529043",
            "0.11145725164416753",
            "0.13029960429621254",
            "0.1677917068466731",
            "0.192847740236946",
            "0.21858440575321728",
            "0.22156084656084654",
            "0.22482758620689652",
            "0.24553571428571427",
            "0.2501512035805008",
            "0.27070270270270264",
            "0.27246860282574564",
            "0.2883612160460514",
            "0.30765507784141327",
            "0.3198014018691589",
            "0.32728014690879415",
            "0.3311907139291064",
            "0.34076812977099236",
            "0.3458378194593983",
            "0.35193899075125745",
            "0.3572497806225159",
            "0.3623464944468907",
            "0.366872263289232",
            "0.377835443604313",
            "0.3822623517995021",
            "0.38715693031175247",
            "0.3939032828476974",
            "0.39968176435760805",
            "0.4014918513804928",
            "0.39687468013238253",
            "0.3924652523774689",
            "0.39395592056719386",
            "0.39838759689922476",
            "0.39880539382786806",
            "0.39997665392359993",
            "0.4057579086734837",
            "0.40862120675082475",
            "0.4116487789288663",
            "0.41344741385975314",
            "0.4138580068763018",
            "0.4180604424736107",
            "0.4166529149673496",
            "0.4211274386190138",
            "0.42491941758363894",
            "0.4256359015574429",
            "0.4283267429320589",
            "0.43020196789228377",
            "0.42981064637256267",
            "0.4331901202597453",
            "0.432961320898945",
            "0.43324565821627764",
            "0.43670863047591313",
            "0.43886682552290174",
            "0.4427087818404146",
            "0.44128997617369703",
            "0.44143519664636655",
            "0.4414877238473381",
            "0.44200098586398245",
            "0.4403024799599197",
            "0.43986856177441597",
            "0.43963480128893656",
            "0.43967536687472597",
            "0.4403001708893676",
            "0.4390415475928775",
            "0.4376933854866016",
            "0.4376933854866016"
        ],
        "args": " --port 8003  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.02,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 2,
        "result_file": "lmsys-reqrate++/client_logs/8003_lru.json"
    },
    {
        "hit_ratios": [],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "request_rate": 0.00125,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.125,
        "result_file": "lmsys-out1000-reqrate/client_logs/8000_ml.json"
    },
    {
        "num_requests": "1035",
        "input_tokens": "63092",
        "output_tokens": "1216190",
        "mean_ttft": "149.95",
        "median_ttft": "126.71",
        "p99_ttft": "511.00",
        "hit_ratios": [
            "0.261878453038674",
            "0.4457350272232305",
            "0.6237003465742469",
            "0.6248670756646217",
            "0.6375082471959533",
            "0.5983586376692652",
            "0.5867217388360358",
            "0.5918879714349474",
            "0.5687519436094122",
            "0.5519874027771149",
            "0.551219744615971"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "request_rate": 0.0025,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 1000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-out1000-reqrate/client_logs/8001_ml.json"
    },
    {
        "num_requests": "1209",
        "input_tokens": "69465",
        "output_tokens": "1418784",
        "mean_ttft": "144.00",
        "median_ttft": "123.85",
        "p99_ttft": "404.12",
        "hit_ratios": [
            "0.18204488778054864",
            "0.4627257799671593",
            "0.5251819937602139",
            "0.5381446991404011",
            "0.5481912471540602",
            "0.520051073489076",
            "0.52221232425733",
            "0.5301370321975408",
            "0.5257648226694341",
            "0.5575322592960222",
            "0.5681191143945097",
            "0.5684859845677669",
            "0.5684859845677669"
        ],
        "args": " --port 8002  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "request_rate": 0.005,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 1000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.5,
        "result_file": "lmsys-out1000-reqrate/client_logs/8002_ml.json"
    },
    {
        "num_requests": "1613",
        "input_tokens": "93087",
        "output_tokens": "1897230",
        "mean_ttft": "146.63",
        "median_ttft": "128.41",
        "p99_ttft": "423.09",
        "hit_ratios": [
            "0.22029988465974626",
            "0.4465691788526434",
            "0.4836297158052185",
            "0.49372715598142847",
            "0.5115754660252556",
            "0.5037516012932349",
            "0.48883455582722085",
            "0.4949579441423859",
            "0.4966116917047682",
            "0.5334063901921167",
            "0.5407168072757733",
            "0.5426978137831541",
            "0.5395304021502105",
            "0.5453253091977445",
            "0.5482751627948899",
            "0.5425450850901703",
            "0.5425450850901703"
        ],
        "args": " --port 8003  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "request_rate": 0.01,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 1000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-out1000-reqrate/client_logs/8003_ml.json"
    },
    {
        "num_requests": "967",
        "input_tokens": "62170",
        "output_tokens": "1136266",
        "mean_ttft": "141.88",
        "median_ttft": "124.82",
        "p99_ttft": "433.47",
        "hit_ratios": [
            "0.2244418331374853",
            "0.5906542056074767",
            "0.707492795389049",
            "0.6904845505617977",
            "0.6246679316888045",
            "0.6028153601273378",
            "0.5647241712533086",
            "0.5446991844899215",
            "0.5270926961160436",
            "0.5227207155222157"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "request_rate": 0.00125,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 1000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.125,
        "result_file": "lmsys-out1000-reqrate/client_logs/8000_ml.json"
    },
    {
        "num_requests": "911",
        "input_tokens": "52683",
        "output_tokens": "2890067",
        "mean_ttft": "186.17",
        "median_ttft": "141.87",
        "p99_ttft": "577.72",
        "hit_ratios": [
            "0.08634868421052631",
            "0.035175879396984924",
            "0.0357462019660411",
            "0.04247437955303123",
            "0.03935532233883057",
            "0.07891846218842416",
            "0.07794984772889264",
            "0.09816875289754289",
            "0.0866046135167948",
            "0.0866046135167948"
        ],
        "args": " --port 8003  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "request_rate": 0.01,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-out3000-reqrate/client_logs/8003_ml.json"
    },
    {
        "num_requests": "782",
        "input_tokens": "48473",
        "output_tokens": "2482722",
        "mean_ttft": "217.76",
        "median_ttft": "195.38",
        "p99_ttft": "604.77",
        "hit_ratios": [
            "0.19014411901441194",
            "0.09691765066707562",
            "0.130092398152037",
            "0.09260385005065856",
            "0.09302325581395347",
            "0.08523790866745026",
            "0.07948676565526146",
            "0.09635397714867913"
        ],
        "args": " --port 8002  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "request_rate": 0.005,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.5,
        "result_file": "lmsys-out3000-reqrate/client_logs/8002_ml.json"
    },
    {
        "num_requests": "618",
        "input_tokens": "41783",
        "output_tokens": "1966245",
        "mean_ttft": "272.61",
        "median_ttft": "199.52",
        "p99_ttft": "1871.52",
        "hit_ratios": [
            "0.04929577464788732",
            "0.3006872852233677",
            "0.2077429778772061",
            "0.15397297732025095",
            "0.15172254182371225",
            "0.1466372657111356",
            "0.1466372657111356"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "request_rate": 0.00125,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.125,
        "result_file": "lmsys-out3000-reqrate/client_logs/8000_ml.json"
    },
    {
        "num_requests": "662",
        "input_tokens": "40381",
        "output_tokens": "2104589",
        "mean_ttft": "584.06",
        "median_ttft": "197.27",
        "p99_ttft": "14862.43",
        "hit_ratios": [
            "0.04933196300102775",
            "0.2657004830917874",
            "0.19236800836382642",
            "0.14386805290947688",
            "0.12683344198174704",
            "0.10778385020858258",
            "0.10796923474663907"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "request_rate": 0.0025,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-out3000-reqrate/client_logs/8001_ml.json"
    },
    {
        "num_requests": "1614",
        "input_tokens": "93142",
        "output_tokens": "1898355",
        "mean_ttft": "137.10",
        "median_ttft": "121.51",
        "p99_ttft": "392.15",
        "hit_ratios": [
            "0.13496143958868895",
            "0.17497348886532346",
            "0.15916875999086552",
            "0.20987987582669726",
            "0.23462117410938285",
            "0.22627201565557734",
            "0.21719955898566704",
            "0.2151994933502217",
            "0.21005486507669918",
            "0.2369483634981712",
            "0.24636487210116578",
            "0.2455183461743841",
            "0.24489012905476115",
            "0.24006011303864883",
            "0.24115655765707017",
            "0.23962165002627436",
            "0.23962165002627436"
        ],
        "args": " --port 8003  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "request_rate": 0.01,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 1000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-out1000-reqrate/client_logs/8003_lru.json"
    },
    {
        "num_requests": "1033",
        "input_tokens": "63078",
        "output_tokens": "1213953",
        "mean_ttft": "142.04",
        "median_ttft": "122.97",
        "p99_ttft": "413.59",
        "hit_ratios": [
            "0.04591836734693878",
            "0.12921890067502412",
            "0.21112107623318385",
            "0.24333001217757114",
            "0.26919219196049693",
            "0.2928370383135161",
            "0.2777751207613947",
            "0.2842126219390803",
            "0.279992637585128",
            "0.27561420086393085",
            "0.27528127736980396"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "request_rate": 0.0025,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 1000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-out1000-reqrate/client_logs/8001_lru.json"
    },
    {
        "num_requests": "1209",
        "input_tokens": "69465",
        "output_tokens": "1418570",
        "mean_ttft": "137.42",
        "median_ttft": "120.99",
        "p99_ttft": "378.40",
        "hit_ratios": [
            "0.019151846785225718",
            "0.0839662447257384",
            "0.18753973299427845",
            "0.2334650184783994",
            "0.2764818008532268",
            "0.26707821721728514",
            "0.26693714222197523",
            "0.27059439394660456",
            "0.2710996341725845",
            "0.2933985330073349",
            "0.3062413045588378",
            "0.3059560350975103",
            "0.3059560350975103"
        ],
        "args": " --port 8002  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "request_rate": 0.005,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 1000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.5,
        "result_file": "lmsys-out1000-reqrate/client_logs/8002_lru.json"
    },
    {
        "num_requests": "967",
        "input_tokens": "62170",
        "output_tokens": "1136266",
        "mean_ttft": "134.86",
        "median_ttft": "119.09",
        "p99_ttft": "391.96",
        "hit_ratios": [
            "0.14429109159347553",
            "0.16582220175034548",
            "0.218498408537727",
            "0.2761175898931001",
            "0.2307968735962627",
            "0.2354315655314027",
            "0.22359988020365382",
            "0.20902755090928893",
            "0.20389743589743586",
            "0.2011714805089881"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "request_rate": 0.00125,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 1000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.125,
        "result_file": "lmsys-out1000-reqrate/client_logs/8000_lru.json"
    },
    {
        "num_requests": "917",
        "input_tokens": "52844",
        "output_tokens": "2909026",
        "mean_ttft": "172.16",
        "median_ttft": "131.25",
        "p99_ttft": "566.06",
        "hit_ratios": [
            "0.09528301886792453",
            "0.039334741288278775",
            "0.031088082901554404",
            "0.039616539616539624",
            "0.03517627573152457",
            "0.04102910291029103",
            "0.03641611397690986",
            "0.04034126221820442",
            "0.04527148333252463",
            "0.045269286754002915"
        ],
        "args": " --port 8003  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "request_rate": 0.01,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-out3000-reqrate/client_logs/8003_lru.json"
    },
    {
        "num_requests": "787",
        "input_tokens": "48703",
        "output_tokens": "2498646",
        "mean_ttft": "191.71",
        "median_ttft": "132.88",
        "p99_ttft": "577.93",
        "hit_ratios": [
            "0.013579576317218903",
            "0.00782319577547428",
            "0.011704834605597963",
            "0.01599407626804887",
            "0.01583265919334335",
            "0.015597843041133744",
            "0.014542310262154624",
            "0.017006928748749494"
        ],
        "args": " --port 8002  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "request_rate": 0.005,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.5,
        "result_file": "lmsys-out3000-reqrate/client_logs/8002_lru.json"
    },
    {
        "num_requests": "666",
        "input_tokens": "40589",
        "output_tokens": "2117160",
        "mean_ttft": "216.75",
        "median_ttft": "183.86",
        "p99_ttft": "602.76",
        "hit_ratios": [
            "0.051648351648351645",
            "0.013403542364767831",
            "0.010684983781721048",
            "0.011902426263815317",
            "0.009525709440925642",
            "0.011670761670761674",
            "0.01188604731413673"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "request_rate": 0.0025,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-out3000-reqrate/client_logs/8001_lru.json"
    },
    {
        "num_requests": "624",
        "input_tokens": "41875",
        "output_tokens": "1985779",
        "mean_ttft": "241.65",
        "median_ttft": "207.19",
        "p99_ttft": "686.48",
        "hit_ratios": [
            "0.04929577464788732",
            "0.04359719610189776",
            "0.018723647538054743",
            "0.014978569817279498",
            "0.014356649395509501",
            "0.016239850093691444",
            "0.016239850093691444"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "request_rate": 0.00125,
        "max_active_conversations": 50,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.125,
        "result_file": "lmsys-out3000-reqrate/client_logs/8000_lru.json"
    },
    {
        "hit_ratios": [],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 3750 ",
        "size": 3750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_ml.json"
    },
    {
        "hit_ratios": [],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 5750 ",
        "size": 5750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8001_ml.json"
    },
    {
        "num_requests": "5022",
        "input_tokens": "313879",
        "output_tokens": "869995",
        "mean_ttft": "171.42",
        "median_ttft": "152.58",
        "p99_ttft": "403.30",
        "hit_ratios": [
            "0.0394088669950739",
            "0.06158730158730158",
            "0.07051282051282051",
            "0.08694070571116769",
            "0.10588935157644258",
            "0.10929108485499463",
            "0.1314086610253858",
            "0.15272878190495953",
            "0.21243102888672508",
            "0.23271760425412819",
            "0.24910857002336168",
            "0.26636175541761953",
            "0.2753219296559677",
            "0.2695644629533229",
            "0.2736369366530098",
            "0.26803746524220695",
            "0.2700900300100034",
            "0.27821490041799857",
            "0.28389009234978907",
            "0.28108398175476257",
            "0.2796476399001986",
            "0.27957141508543376",
            "0.29135693864086215",
            "0.2947442302134511",
            "0.2932132746146586",
            "0.29664385073967753",
            "0.29460580912863055",
            "0.2945874001774622",
            "0.2950798884098401",
            "0.2983595560434199",
            "0.29817835937049625",
            "0.29637703153886474",
            "0.2970888811804573",
            "0.3013245033112582",
            "0.30112044817927164",
            "0.30333799909847914",
            "0.30356897420625817",
            "0.30300517670259725",
            "0.3024858585639669",
            "0.3021078748201738",
            "0.3040603577657891",
            "0.3039277670209823",
            "0.3066016161000152",
            "0.3041435843689174",
            "0.301835249252883",
            "0.29967163697044724",
            "0.29800010535002536",
            "0.29477063906821044",
            "0.29102193218514527",
            "0.29102193218514527",
            "0.29102193218514527"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 5750 ",
        "size": 5750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8001_ml.json"
    },
    {
        "num_requests": "5020",
        "input_tokens": "313814",
        "output_tokens": "871287",
        "mean_ttft": "170.78",
        "median_ttft": "152.70",
        "p99_ttft": "386.79",
        "hit_ratios": [
            "0.0394088669950739",
            "0.061121613106490225",
            "0.06854043392504931",
            "0.07581891792418109",
            "0.09458655562165377",
            "0.09750201450443191",
            "0.10439146800501883",
            "0.12068248023304204",
            "0.148328464784161",
            "0.17226420375034987",
            "0.17938271604938275",
            "0.19054894685146787",
            "0.19863540265231597",
            "0.19651223321186884",
            "0.19457370455083212",
            "0.19010683447973073",
            "0.1878040653115628",
            "0.19154167691172855",
            "0.18785632839224634",
            "0.18610142205527233",
            "0.18636386781404352",
            "0.1841782309072029",
            "0.18699115433701538",
            "0.18914446466986595",
            "0.18784421715184893",
            "0.1859815488661007",
            "0.18319817009773348",
            "0.18186608701379972",
            "0.17769358125318394",
            "0.18128099932643443",
            "0.17806951593314446",
            "0.1769284032682455",
            "0.18101032743575382",
            "0.18307684519590975",
            "0.18327310273619007",
            "0.18483502387343526",
            "0.18320698105861075",
            "0.18200991720702742",
            "0.18035454683533325",
            "0.1807384833747314",
            "0.18570239714210335",
            "0.18367387266332066",
            "0.18507992217601965",
            "0.1834838322904569",
            "0.1815697279847394",
            "0.18024686921681024",
            "0.17984460694698368",
            "0.17651175095151145",
            "0.17476937579960955",
            "0.17476937579960955",
            "0.17476937579960955"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 3750 ",
        "size": 3750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_ml.json"
    },
    {
        "num_requests": "5037",
        "input_tokens": "314275",
        "output_tokens": "871761",
        "mean_ttft": "168.64",
        "median_ttft": "149.21",
        "p99_ttft": "403.83",
        "hit_ratios": [
            "0.03685258964143426",
            "0.061862244897959176",
            "0.07007007007007007",
            "0.06599552572706935",
            "0.07272727272727272",
            "0.07323026851098453",
            "0.07021063189568705",
            "0.07672903090182889",
            "0.10668210387032749",
            "0.11621621621621622",
            "0.11480324797001873",
            "0.12537412703691386",
            "0.1307880567792462",
            "0.12790389541559932",
            "0.12271077047196452",
            "0.11777877295118676",
            "0.1266539353430637",
            "0.13470721286755463",
            "0.13546165518851405",
            "0.13485420427813333",
            "0.1348461137193531",
            "0.13038219641993226",
            "0.13036990141991497",
            "0.12930011862396204",
            "0.13237736460485278",
            "0.13181852666717248",
            "0.13553754418538225",
            "0.13648097826086958",
            "0.13758334154432295",
            "0.13959077828025684",
            "0.13711315569363128",
            "0.13647153029999717",
            "0.1414138633485658",
            "0.13897914264752126",
            "0.13735829830594828",
            "0.13756678895920027",
            "0.13689470553242117",
            "0.13565116279069767",
            "0.13454374074240313",
            "0.13423834331294177",
            "0.13615349052242254",
            "0.1361534999795442",
            "0.13454818266174406",
            "0.13675478719280565",
            "0.13644302692030225",
            "0.1363890754421312",
            "0.13454122098522883",
            "0.13192332177972696",
            "0.13041967156138676",
            "0.13033891242447393",
            "0.13033891242447393"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 4000 ",
        "size": 4000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_lru.json"
    },
    {
        "num_requests": "5030",
        "input_tokens": "314006",
        "output_tokens": "871786",
        "mean_ttft": "169.37",
        "median_ttft": "151.61",
        "p99_ttft": "384.86",
        "hit_ratios": [
            "0.03933136676499509",
            "0.06163934426229509",
            "0.06986027944111775",
            "0.09097688292319164",
            "0.11151515151515153",
            "0.11266846361185984",
            "0.11203007518796991",
            "0.13085690164626423",
            "0.1741219350563287",
            "0.1952544311034877",
            "0.20610016317308902",
            "0.22252070740989482",
            "0.23290640394088669",
            "0.2262487757100881",
            "0.22320486815415821",
            "0.22035045498984732",
            "0.232144079983565",
            "0.2416703407444731",
            "0.24318168545231555",
            "0.23897464167585442",
            "0.242239932885906",
            "0.2373485736615865",
            "0.23936533989878261",
            "0.24038667179947812",
            "0.2442651155169589",
            "0.24804187521491616",
            "0.25127780577352243",
            "0.25618900873138156",
            "0.25707391246859707",
            "0.2599923503537961",
            "0.26001329064217954",
            "0.2570659877918245",
            "0.2611041229909154",
            "0.26020245919016316",
            "0.25757575757575746",
            "0.25699942556007876",
            "0.2565475469412476",
            "0.25408463986797103",
            "0.25276647958372134",
            "0.2506111402130259",
            "0.25267251822413017",
            "0.25191739193351664",
            "0.2499251242936725",
            "0.25039188024139825",
            "0.24821387416455404",
            "0.2477150487080152",
            "0.2430218279786669",
            "0.24005004021088375",
            "0.23692021285937584",
            "0.23692021285937584",
            "0.23692021285937584"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 6000 ",
        "size": 6000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8001_lru.json"
    },
    {
        "num_requests": "4955",
        "input_tokens": "309965",
        "output_tokens": "859922",
        "mean_ttft": "170.09",
        "median_ttft": "151.85",
        "p99_ttft": "386.05",
        "hit_ratios": [
            "0.03933136676499509",
            "0.06158730158730158",
            "0.06986027944111775",
            "0.08483954260420509",
            "0.106184012066365",
            "0.10522044901271299",
            "0.10612968591691994",
            "0.11769616026711184",
            "0.15219917012448134",
            "0.18285551276565398",
            "0.19269061121613104",
            "0.21261421885446846",
            "0.22388790907309425",
            "0.2176413341590728",
            "0.21574955623688885",
            "0.21550689862027594",
            "0.2290643753409711",
            "0.2374787909256583",
            "0.23946539045173343",
            "0.2366776315789474",
            "0.2403088641936662",
            "0.23876186785506687",
            "0.24159035270650106",
            "0.2425027610228528",
            "0.2464823098820659",
            "0.24962869873186339",
            "0.25119832774714385",
            "0.25595340071954775",
            "0.2549188473004306",
            "0.25802646261756734",
            "0.2584005072004348",
            "0.25608909459068563",
            "0.26149817533498626",
            "0.2591649424372646",
            "0.255727649923975",
            "0.25472144119037554",
            "0.25423444172544507",
            "0.2527488018043418",
            "0.2514003220173709",
            "0.24912854030501094",
            "0.25108813350601933",
            "0.25054700078437847",
            "0.2482055985325784",
            "0.2488547825065581",
            "0.2463551831018253",
            "0.24606819502502483",
            "0.24242924485041914",
            "0.23950068950695777",
            "0.23826399772047302",
            "0.23826399772047302"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 6000 ",
        "size": 6000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8001_lru.json"
    },
    {
        "num_requests": "4957",
        "input_tokens": "309974",
        "output_tokens": "859467",
        "mean_ttft": "168.07",
        "median_ttft": "149.94",
        "p99_ttft": "372.54",
        "hit_ratios": [
            "0.03944773175542406",
            "0.061626429479034316",
            "0.0707070707070707",
            "0.06599552572706935",
            "0.07299270072992702",
            "0.07313109425785481",
            "0.07045797684952188",
            "0.07684188304834283",
            "0.10968921389396709",
            "0.11986202931876977",
            "0.11753590325018898",
            "0.1287028725314183",
            "0.1318887899475611",
            "0.12899767732713951",
            "0.12442885117493471",
            "0.11972150749205386",
            "0.1282704489121454",
            "0.13640687424694017",
            "0.13821712268314207",
            "0.13708914965797228",
            "0.13662068601025315",
            "0.13337916809900308",
            "0.13235766389870166",
            "0.13121392263289391",
            "0.13501709859503108",
            "0.13461538461538458",
            "0.13742988271290157",
            "0.13862863488097715",
            "0.13936920967256428",
            "0.1376858227685179",
            "0.13497287743036507",
            "0.13462268836366822",
            "0.1398160906611175",
            "0.13750668806848582",
            "0.13607265535547",
            "0.13569402966346275",
            "0.13516528825398366",
            "0.13392095535968151",
            "0.13278643572048807",
            "0.13283775759308533",
            "0.13488143348942622",
            "0.13486910558954504",
            "0.13344709897610915",
            "0.13559021274078742",
            "0.13460907810721653",
            "0.13473428668967866",
            "0.13316420066295065",
            "0.13088391714290862",
            "0.13019172191363554",
            "0.13019172191363554"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 4000 ",
        "size": 4000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_lru.json"
    },
    {
        "num_requests": "5027",
        "input_tokens": "313986",
        "output_tokens": "872265",
        "mean_ttft": "163.92",
        "median_ttft": "146.58",
        "p99_ttft": "357.63",
        "hit_ratios": [
            "0.03681592039800995",
            "0.060082872928176795",
            "0.07063572149344097",
            "0.09375000000000001",
            "0.11978221415607984",
            "0.13052858683926644",
            "0.16141047926496152",
            "0.20307628351694038",
            "0.2722411278561011",
            "0.30635918937805734",
            "0.3256299938537185",
            "0.3439947780678851",
            "0.35084013442150747",
            "0.34294621979734996",
            "0.35643330179754024",
            "0.3545296167247387",
            "0.3523295340931814",
            "0.3585427290041162",
            "0.3656201925816194",
            "0.3664253150978815",
            "0.36390472312703587",
            "0.3666902571361171",
            "0.37571047957371234",
            "0.38333470699744515",
            "0.3871727440436473",
            "0.3926668871009223",
            "0.39527015363369594",
            "0.39893023561068464",
            "0.40048751147551376",
            "0.40260649797509224",
            "0.40527936900889505",
            "0.40056771206525943",
            "0.3999840463718791",
            "0.40079125088196765",
            "0.40224162456467366",
            "0.4072098976109215",
            "0.40658684010939766",
            "0.4063694267515924",
            "0.40570738336101464",
            "0.40225041001473977",
            "0.4050740470988103",
            "0.4048936044566051",
            "0.4051933743636501",
            "0.40289903738526966",
            "0.4002558713332723",
            "0.39762994882844055",
            "0.3939457604566065",
            "0.38830730409875186",
            "0.384399946333937",
            "0.3841744464743643",
            "0.3841744464743643"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 7750 ",
        "size": 7750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_ml.json"
    },
    {
        "num_requests": "5028",
        "input_tokens": "313990",
        "output_tokens": "871462",
        "mean_ttft": "162.57",
        "median_ttft": "143.51",
        "p99_ttft": "341.68",
        "hit_ratios": [
            "0.03681592039800995",
            "0.060082872928176795",
            "0.06979062811565304",
            "0.09371513573819264",
            "0.12012102874432676",
            "0.1343042071197411",
            "0.16786689843555996",
            "0.22926626480981088",
            "0.30238210986874087",
            "0.33240145373217783",
            "0.3576516826332597",
            "0.37461840383776707",
            "0.3829092654824772",
            "0.3788862908114662",
            "0.39604350567465313",
            "0.3975824655938251",
            "0.4070519229487436",
            "0.41358972783682496",
            "0.4173214895797745",
            "0.4210469856254023",
            "0.4237581433224756",
            "0.4357631516867186",
            "0.44644820760941273",
            "0.45366739588062893",
            "0.459318306761957",
            "0.46711374774310027",
            "0.47408278294546835",
            "0.4771651991063214",
            "0.4790022503248708",
            "0.48160229247324937",
            "0.4809371487853376",
            "0.4804127124255131",
            "0.4793245117916977",
            "0.4818897240579124",
            "0.48316977428851815",
            "0.4869051572804478",
            "0.4862477689808247",
            "0.4838392198089785",
            "0.48153185242751984",
            "0.4807185131346693",
            "0.4828891948809331",
            "0.48191178791226136",
            "0.48359595036918623",
            "0.485027588141775",
            "0.48158438282549487",
            "0.47812112832851533",
            "0.473341273733623",
            "0.46939471440750224",
            "0.4664183486854248",
            "0.4659738518270199",
            "0.4659738518270199"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8001_ml.json"
    },
    {
        "num_requests": "4956",
        "input_tokens": "309970",
        "output_tokens": "860185",
        "mean_ttft": "165.88",
        "median_ttft": "144.52",
        "p99_ttft": "372.77",
        "hit_ratios": [
            "0.0394088669950739",
            "0.06158730158730158",
            "0.06979062811565304",
            "0.08796466691203533",
            "0.11386288130474176",
            "0.12459807073954983",
            "0.15669232679413955",
            "0.19912700062357097",
            "0.26916221033868093",
            "0.3037037037037037",
            "0.3233849177106362",
            "0.3407827319306661",
            "0.3490158425348056",
            "0.3409543604399411",
            "0.3522557278954413",
            "0.34632541133455214",
            "0.34906352062920754",
            "0.3555323462554525",
            "0.3627713520597118",
            "0.36374363100026824",
            "0.3613599348534202",
            "0.3645199339466856",
            "0.3774190710767065",
            "0.37937991518096104",
            "0.3836220472440945",
            "0.39017479300827956",
            "0.3927952892275718",
            "0.39659599683961017",
            "0.3975700518431347",
            "0.40003060443764343",
            "0.40268262365218394",
            "0.39830555401738743",
            "0.398015259030038",
            "0.3990066644705167",
            "0.40000492222878514",
            "0.40586361042419633",
            "0.4063648897058823",
            "0.4040742071691672",
            "0.40282785283002476",
            "0.3991099782717701",
            "0.40291626896285615",
            "0.40158570101034063",
            "0.4020465045244549",
            "0.3998462490390564",
            "0.3968640668217536",
            "0.39404883833755594",
            "0.3910452483915199",
            "0.38672277567846103",
            "0.385100061471211",
            "0.385100061471211"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 7750 ",
        "size": 7750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_ml.json"
    },
    {
        "num_requests": "4960",
        "input_tokens": "310086",
        "output_tokens": "859507",
        "mean_ttft": "163.36",
        "median_ttft": "146.19",
        "p99_ttft": "318.91",
        "hit_ratios": [
            "0.0394088669950739",
            "0.06158730158730158",
            "0.07051282051282051",
            "0.09537892791127542",
            "0.12008469449485783",
            "0.13344051446945338",
            "0.16786689843555996",
            "0.22926626480981088",
            "0.30238210986874087",
            "0.3323549965059399",
            "0.3581943081452405",
            "0.37483716891011726",
            "0.3829092654824773",
            "0.3787996882307093",
            "0.39596469104665827",
            "0.39685085289400795",
            "0.40695814449480144",
            "0.41352829145419917",
            "0.4175260668907755",
            "0.4209933490667239",
            "0.42370724755700323",
            "0.43533852323661243",
            "0.4459792363188457",
            "0.4536317008603574",
            "0.4594201188087651",
            "0.46715382344257456",
            "0.4736314278797939",
            "0.4766318280418063",
            "0.4784883167940141",
            "0.48112114188117605",
            "0.4804704390187656",
            "0.4799657817760361",
            "0.47966590169183965",
            "0.48227397744190154",
            "0.4835439931279911",
            "0.48726832625358923",
            "0.48687826325913713",
            "0.48424774008771143",
            "0.4819253692666494",
            "0.4810968009970918",
            "0.4833012658227848",
            "0.48276269883507783",
            "0.4843851040359085",
            "0.48482754757147395",
            "0.48165087263546885",
            "0.4781460048165055",
            "0.47194644480178977",
            "0.46894192113591654",
            "0.4678491862383292",
            "0.4678491862383292"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8001_ml.json"
    },
    {
        "num_requests": "5041",
        "input_tokens": "314520",
        "output_tokens": "873779",
        "mean_ttft": "164.10",
        "median_ttft": "143.34",
        "p99_ttft": "366.12",
        "hit_ratios": [
            "0.03685258964143426",
            "0.06254158349966733",
            "0.06993006993006994",
            "0.08568249258160238",
            "0.10752360645750837",
            "0.1180158081221041",
            "0.127927474187862",
            "0.15459757910384372",
            "0.21592978970028148",
            "0.2518253400143164",
            "0.2614321608040201",
            "0.28412132024977693",
            "0.29334647609659925",
            "0.2995379420650435",
            "0.29720986655883536",
            "0.29597250242845397",
            "0.30535811919081457",
            "0.31839919456330223",
            "0.3168507802910748",
            "0.31260328302302515",
            "0.31385598993816155",
            "0.31049739874556326",
            "0.3181549109785529",
            "0.32395450269391945",
            "0.33306228655065867",
            "0.33579406364749076",
            "0.33666570771001153",
            "0.3424756034925526",
            "0.34492332099418294",
            "0.34752358865203165",
            "0.34707438811714475",
            "0.3436304541663071",
            "0.3453669941826482",
            "0.3493571088417377",
            "0.3501254930082467",
            "0.35169596434761086",
            "0.350283299721502",
            "0.3476142512473356",
            "0.34578741315712064",
            "0.3425944042261789",
            "0.34397328034498803",
            "0.34485381800238507",
            "0.3468906630742716",
            "0.3477201870615745",
            "0.3448177242220867",
            "0.34369732159580446",
            "0.33903872121455425",
            "0.33440326298989187",
            "0.3303192696423273",
            "0.32949204470285137",
            "0.32949204470285137"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 8000 ",
        "size": 8000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_lru.json"
    },
    {
        "num_requests": "5044",
        "input_tokens": "314836",
        "output_tokens": "873001",
        "mean_ttft": "162.65",
        "median_ttft": "145.67",
        "p99_ttft": "344.78",
        "hit_ratios": [
            "0.039525691699604744",
            "0.06460481099656357",
            "0.06986027944111775",
            "0.08389261744966442",
            "0.10814950980392156",
            "0.12339961863252517",
            "0.15084361621757741",
            "0.19584569732937684",
            "0.2641102257636122",
            "0.2944300890037324",
            "0.31911413111866105",
            "0.33201312662668325",
            "0.3410829607550919",
            "0.3428340951868782",
            "0.3496400523560209",
            "0.3564766059876635",
            "0.36168307967770813",
            "0.37691281986157843",
            "0.3766501650165016",
            "0.37545991749358903",
            "0.3761977870718407",
            "0.37583529874213834",
            "0.38440316350928816",
            "0.3915337051930643",
            "0.40121981373114646",
            "0.40710530385031696",
            "0.41178183936503304",
            "0.4154128186503407",
            "0.4210105052526263",
            "0.42306706809301126",
            "0.42387842387842384",
            "0.4240237443985334",
            "0.4259512958872703",
            "0.42508238545763793",
            "0.42568109492639256",
            "0.4273995283728864",
            "0.42750090942160784",
            "0.4238484310242748",
            "0.42231967475218135",
            "0.42111381632339717",
            "0.4224574911774142",
            "0.4240472133327792",
            "0.42389623948440985",
            "0.4245364891518738",
            "0.42364456090324076",
            "0.4226069825152968",
            "0.41723084848038855",
            "0.4164381106032088",
            "0.4121384943056803",
            "0.41154555838678497",
            "0.41154555838678497"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8001_lru.json"
    },
    {
        "num_requests": "5016",
        "input_tokens": "313751",
        "output_tokens": "868184",
        "mean_ttft": "168.29",
        "median_ttft": "148.90",
        "p99_ttft": "358.77",
        "hit_ratios": [
            "0.03944773175542406",
            "0.061626429479034316",
            "0.06986027944111775",
            "0.09097688292319164",
            "0.11327649208282582",
            "0.12246003793010024",
            "0.13294651866801208",
            "0.15819567979669633",
            "0.21925754060324826",
            "0.25401606425702816",
            "0.2610229276895944",
            "0.2824427480916031",
            "0.292025755324418",
            "0.29657454610499956",
            "0.2950472466601499",
            "0.291216675477683",
            "0.30487302676733014",
            "0.31747037576832904",
            "0.31573687613896895",
            "0.31203195207189216",
            "0.31305677086078754",
            "0.3106268364348677",
            "0.3202329634045676",
            "0.32458748007410276",
            "0.33388232387697114",
            "0.3373787345881807",
            "0.3398975402390727",
            "0.3454124637280641",
            "0.34749858347498586",
            "0.35028049366885716",
            "0.3508570044212949",
            "0.34732624978226795",
            "0.3490068454718887",
            "0.3504937844384699",
            "0.35155542913294197",
            "0.3528618182726659",
            "0.3521408756482933",
            "0.34923592113951507",
            "0.3464894342194956",
            "0.3433920272304772",
            "0.3457131316567104",
            "0.34624927632123076",
            "0.3483594295402414",
            "0.34847505435740733",
            "0.34569368816627044",
            "0.34420549131859446",
            "0.34015655433464415",
            "0.33553981479829437",
            "0.33167542487565693",
            "0.33167542487565693",
            "0.33167542487565693"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 8000 ",
        "size": 8000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8000_lru.json"
    },
    {
        "num_requests": "5017",
        "input_tokens": "313757",
        "output_tokens": "869016",
        "mean_ttft": "164.44",
        "median_ttft": "146.31",
        "p99_ttft": "340.68",
        "hit_ratios": [
            "0.039525691699604744",
            "0.06012439530062197",
            "0.06986027944111775",
            "0.08475836431226766",
            "0.10736009732360097",
            "0.12339961863252517",
            "0.15069182389937105",
            "0.1960950764006791",
            "0.2636815920398009",
            "0.29968634160250923",
            "0.3236177132849637",
            "0.33790871554514007",
            "0.34199861619057026",
            "0.34362176628010704",
            "0.3524423061241132",
            "0.3570191945803538",
            "0.3630358494460883",
            "0.37866413421968975",
            "0.37921711531679797",
            "0.37868707030383675",
            "0.3799020898036532",
            "0.376063361689645",
            "0.38325849903784476",
            "0.38966408268733854",
            "0.40143266475644696",
            "0.4075141177826438",
            "0.4119051926904288",
            "0.41631727266478796",
            "0.42196665893348356",
            "0.4233072170201923",
            "0.4251052315093205",
            "0.42482024733966056",
            "0.42533476312243945",
            "0.4257960776043863",
            "0.4269170659219595",
            "0.4290658294811262",
            "0.4298180601047171",
            "0.4260224960830626",
            "0.4243032833126481",
            "0.42302273663220413",
            "0.4239536898147171",
            "0.42466739322654284",
            "0.42494605776273336",
            "0.4249164659258684",
            "0.4247570507578496",
            "0.42328329189179087",
            "0.41778520442450556",
            "0.4165941655865486",
            "0.4120675812476001",
            "0.4120675812476001",
            "0.4120675812476001"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 0,
        "algorithm": "lru",
        "session_rate": 10,
        "request_rate": 0.01,
        "max_active_conversations": 200,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 1200,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-size++/client_logs/8001_lru.json"
    },
    {
        "num_requests": "1741",
        "input_tokens": "100257",
        "output_tokens": "5533928",
        "mean_ttft": "89149.57",
        "median_ttft": "81858.32",
        "p99_ttft": "259206.87",
        "hit_ratios": [
            "0.1344551678627403",
            "0.13610853329798045",
            "0.11884233071558019",
            "0.12331110979998822",
            "0.12216276065694778",
            "0.12744148095262378",
            "0.1275936083949439",
            "0.12476137108339905",
            "0.12370084418614516",
            "0.12296907405848449",
            "0.12283549029714552",
            "0.12317120622568087",
            "0.12753473638741566",
            "0.1272179840660363",
            "0.1277586566820647",
            "0.12878027118541444",
            "0.12830114790611172",
            "0.12830114790611172"
        ],
        "args": " --port 8003  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "request_rate": 0.01,
        "max_active_conversations": 100,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-out3000-100-reqrate/client_logs/8003_ml.json"
    },
    {
        "num_requests": "1214",
        "input_tokens": "75503",
        "output_tokens": "3857986",
        "mean_ttft": "81663.37",
        "median_ttft": "57139.37",
        "p99_ttft": "292274.09",
        "hit_ratios": [
            "0.11145564168819981",
            "0.1505942530464871",
            "0.13070461384152457",
            "0.10778201390446286",
            "0.09937341811222915",
            "0.10155205348615089",
            "0.0930140077743645",
            "0.10205013351709882",
            "0.09789682165424884",
            "0.09771454211234788",
            "0.09734570874393056",
            "0.09798386089389667",
            "0.09798386089389667"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "request_rate": 0.0025,
        "max_active_conversations": 100,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-out3000-100-reqrate/client_logs/8001_ml.json"
    },
    {
        "num_requests": "1423",
        "input_tokens": "84963",
        "output_tokens": "4520676",
        "mean_ttft": "110516.95",
        "median_ttft": "104095.25",
        "p99_ttft": "343386.52",
        "hit_ratios": [
            "0.15363591996095657",
            "0.12974161627267722",
            "0.11365143357292518",
            "0.12026891505404298",
            "0.11815533431383639",
            "0.12119540337821182",
            "0.11799825113324555",
            "0.11751717369970557",
            "0.11683265490000479",
            "0.11601036980336363",
            "0.12116712205810527",
            "0.11812234315173803",
            "0.1211836623181476",
            "0.12122859323439135",
            "0.12122859323439135"
        ],
        "args": " --port 8002  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "request_rate": 0.005,
        "max_active_conversations": 100,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.5,
        "result_file": "lmsys-out3000-100-reqrate/client_logs/8002_ml.json"
    },
    {
        "num_requests": "1187",
        "input_tokens": "76974",
        "output_tokens": "3772535",
        "mean_ttft": "121617.68",
        "median_ttft": "42431.82",
        "p99_ttft": "568281.37",
        "hit_ratios": [
            "0.14934242571846082",
            "0.1339722887800813",
            "0.12403257830544193",
            "0.10445258647456997",
            "0.1217557807979687",
            "0.11923355480681425",
            "0.11392096275817205",
            "0.10916449282363418",
            "0.10421663302893446",
            "0.09859035522431771",
            "0.09884107699310248",
            "0.10145278115669581"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 9750 ",
        "size": 9750,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "ml",
        "request_rate": 0.00125,
        "max_active_conversations": 100,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.125,
        "result_file": "lmsys-out3000-100-reqrate/client_logs/8000_ml.json"
    },
    {
        "num_requests": "1737",
        "input_tokens": "100212",
        "output_tokens": "5521545",
        "mean_ttft": "68755.98",
        "median_ttft": "57569.53",
        "p99_ttft": "218569.27",
        "hit_ratios": [
            "0.05127073773385103",
            "0.06539661837998975",
            "0.05761062195842357",
            "0.06259885124448514",
            "0.059289054579940464",
            "0.061340709404490705",
            "0.06551193965310141",
            "0.062023860114636356",
            "0.06034735185388528",
            "0.05810910886200936",
            "0.05901579252833183",
            "0.0593623659542815",
            "0.06171705145460188",
            "0.06328694905903265",
            "0.06330811831485383",
            "0.06365203553905319",
            "0.06319245637019426",
            "0.06319245637019426"
        ],
        "args": " --port 8003  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "request_rate": 0.01,
        "max_active_conversations": 100,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 1,
        "result_file": "lmsys-out3000-100-reqrate/client_logs/8003_lru.json"
    },
    {
        "num_requests": "1424",
        "input_tokens": "85063",
        "output_tokens": "4523996",
        "mean_ttft": "102565.02",
        "median_ttft": "98079.13",
        "p99_ttft": "308218.17",
        "hit_ratios": [
            "0.06588285139286092",
            "0.05163930433088126",
            "0.037322848507966286",
            "0.033113532110091715",
            "0.038857756966300734",
            "0.036114647319828434",
            "0.04529539558330343",
            "0.042499081894968774",
            "0.04551057559653547",
            "0.046524271266216825",
            "0.04525398191993111",
            "0.045866261588967464",
            "0.04540198651758146",
            "0.046408069404071786",
            "0.046408069404071786"
        ],
        "args": " --port 8002  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "request_rate": 0.005,
        "max_active_conversations": 100,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.5,
        "result_file": "lmsys-out3000-100-reqrate/client_logs/8002_lru.json"
    },
    {
        "num_requests": "1217",
        "input_tokens": "75535",
        "output_tokens": "3867541",
        "mean_ttft": "61123.66",
        "median_ttft": "38735.18",
        "p99_ttft": "244211.50",
        "hit_ratios": [
            "0.04147378365611715",
            "0.057172164336230645",
            "0.04999356582164455",
            "0.04419433236591867",
            "0.04822838008678715",
            "0.04278818406002411",
            "0.04022238490838291",
            "0.04212171355028496",
            "0.04162071846282371",
            "0.04169535317279203",
            "0.041771158776636716",
            "0.04169683122679542",
            "0.04169683122679542"
        ],
        "args": " --port 8001  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "request_rate": 0.0025,
        "max_active_conversations": 100,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.25,
        "result_file": "lmsys-out3000-100-reqrate/client_logs/8001_lru.json"
    },
    {
        "num_requests": "1192",
        "input_tokens": "77101",
        "output_tokens": "3788418",
        "mean_ttft": "110284.52",
        "median_ttft": "31227.90",
        "p99_ttft": "559336.60",
        "hit_ratios": [
            "0.06114032374471597",
            "0.05791227096057746",
            "0.04845796002756719",
            "0.03740845813815398",
            "0.045209716844405036",
            "0.04532487044008171",
            "0.045061222181376016",
            "0.04211630188423936",
            "0.03800007260582297",
            "0.03803191282047283",
            "0.03732352004529209",
            "0.03762184467041411"
        ],
        "args": " --port 8000  --eviction_algorithm ml --max-num-batched-tokens 2048 --num-gpu-blocks-override 10000 ",
        "size": 10000,
        "num_prompts": 30000,
        "use_oracle": 0,
        "use_token_id": 1,
        "algorithm": "lru",
        "request_rate": 0.00125,
        "max_active_conversations": 100,
        "checkpoint": "/home/dy5/vllm/benchmarks/checkpoints_lmsys-chat-1m_20/lmsys-chat-1m_epoch11_metric_0_5797.pt",
        "dataset_file": "\"lmsys/lmsys-chat-1m\"",
        "time_limit": 3600,
        "sharegpt-output-len": 3000,
        "session_rate": 1,
        "dataset_name": "lmsys",
        "scale": 0.125,
        "result_file": "lmsys-out3000-100-reqrate/client_logs/8000_lru.json"
    }
]